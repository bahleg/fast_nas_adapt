{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb1cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.fx\n",
    "from torch.fx.node import Node\n",
    "\n",
    "from typing import Dict\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129cbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Inception_V3_Weights.IMAGENET1K_V1\n",
    "model = inception_v3(weights=weights)\n",
    "traced_graph = torch.fx.symbolic_trace(model)\n",
    "x = torch.rand(3, 3, 299, 299)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c51050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphInterperterWithGamma(nn.Module): \n",
    "    \"\"\"\n",
    "    класс, но с гаммами для нод\n",
    "    \"\"\"\n",
    "    def __init__(self, mod):\n",
    "        super(GraphInterperterWithGamma, self).__init__()\n",
    "        self.mod = mod\n",
    "        self.graph = mod.graph\n",
    "        self.modules = dict(self.mod.named_modules())\n",
    "        gammas = []\n",
    "        self.gammas_name = {}\n",
    "        i = 0\n",
    "        for node in self.graph.nodes:\n",
    "            if node.op == 'call_module':\n",
    "                gammas.append(1.0)\n",
    "                self.gammas_name[str(node)] = i# перевод в str тут для удобства. в реалньых методах это не нужно\n",
    "                i+=1                        # да и вообще, тут по идее должен быть тензор/параметр\n",
    "        self.gammas = nn.Parameter(torch.as_tensor(gammas), requires_grad = False)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        args_iter = iter(args)\n",
    "        env : Dict[str, Node] = {}\n",
    "\n",
    "        def load_arg(a):\n",
    "            return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "        def fetch_attr(target : str):\n",
    "            target_atoms = target.split('.')\n",
    "            attr_itr = self.mod\n",
    "            for i, atom in enumerate(target_atoms):\n",
    "                if not hasattr(attr_itr, atom):\n",
    "                    raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "                attr_itr = getattr(attr_itr, atom)\n",
    "            return attr_itr\n",
    "        \n",
    "\n",
    "        for node in self.graph.nodes:\n",
    "            if node.op == 'placeholder':\n",
    "                result = next(args_iter)\n",
    "            elif node.op == 'get_attr':\n",
    "                result = fetch_attr(node.target)\n",
    "            elif node.op == 'call_function':\n",
    "                result = node.target(*load_arg(node.args), **load_arg(node.kwargs))\n",
    "            elif node.op == 'call_method':\n",
    "                self_obj, *args = load_arg(node.args)\n",
    "                kwargs = load_arg(node.kwargs)\n",
    "                result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "            elif node.op == 'call_module':\n",
    "                result = self.modules[node.target](*load_arg(node.args), **load_arg(node.kwargs)) * self.gammas[self.gammas_name[str(node)]]\n",
    "            if node.op == 'output':\n",
    "                return result\n",
    "                        \n",
    "            env[node.name] = result\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0f007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_graph = GraphInterperterWithGamma(traced_graph).to('cpu')\n",
    "for i in range(len(gamma_graph.gammas)):\n",
    "    gamma_graph.gammas[i] = 1 #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7cd3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv2d_1a_3x3_conv': 0,\n",
       " 'conv2d_1a_3x3_bn': 1,\n",
       " 'conv2d_2a_3x3_conv': 2,\n",
       " 'conv2d_2a_3x3_bn': 3,\n",
       " 'conv2d_2b_3x3_conv': 4,\n",
       " 'conv2d_2b_3x3_bn': 5,\n",
       " 'maxpool1': 6,\n",
       " 'conv2d_3b_1x1_conv': 7,\n",
       " 'conv2d_3b_1x1_bn': 8,\n",
       " 'conv2d_4a_3x3_conv': 9,\n",
       " 'conv2d_4a_3x3_bn': 10,\n",
       " 'maxpool2': 11,\n",
       " 'mixed_5b_branch1x1_conv': 12,\n",
       " 'mixed_5b_branch1x1_bn': 13,\n",
       " 'mixed_5b_branch5x5_1_conv': 14,\n",
       " 'mixed_5b_branch5x5_1_bn': 15,\n",
       " 'mixed_5b_branch5x5_2_conv': 16,\n",
       " 'mixed_5b_branch5x5_2_bn': 17,\n",
       " 'mixed_5b_branch3x3dbl_1_conv': 18,\n",
       " 'mixed_5b_branch3x3dbl_1_bn': 19,\n",
       " 'mixed_5b_branch3x3dbl_2_conv': 20,\n",
       " 'mixed_5b_branch3x3dbl_2_bn': 21,\n",
       " 'mixed_5b_branch3x3dbl_3_conv': 22,\n",
       " 'mixed_5b_branch3x3dbl_3_bn': 23,\n",
       " 'mixed_5b_branch_pool_conv': 24,\n",
       " 'mixed_5b_branch_pool_bn': 25,\n",
       " 'mixed_5c_branch1x1_conv': 26,\n",
       " 'mixed_5c_branch1x1_bn': 27,\n",
       " 'mixed_5c_branch5x5_1_conv': 28,\n",
       " 'mixed_5c_branch5x5_1_bn': 29,\n",
       " 'mixed_5c_branch5x5_2_conv': 30,\n",
       " 'mixed_5c_branch5x5_2_bn': 31,\n",
       " 'mixed_5c_branch3x3dbl_1_conv': 32,\n",
       " 'mixed_5c_branch3x3dbl_1_bn': 33,\n",
       " 'mixed_5c_branch3x3dbl_2_conv': 34,\n",
       " 'mixed_5c_branch3x3dbl_2_bn': 35,\n",
       " 'mixed_5c_branch3x3dbl_3_conv': 36,\n",
       " 'mixed_5c_branch3x3dbl_3_bn': 37,\n",
       " 'mixed_5c_branch_pool_conv': 38,\n",
       " 'mixed_5c_branch_pool_bn': 39,\n",
       " 'mixed_5d_branch1x1_conv': 40,\n",
       " 'mixed_5d_branch1x1_bn': 41,\n",
       " 'mixed_5d_branch5x5_1_conv': 42,\n",
       " 'mixed_5d_branch5x5_1_bn': 43,\n",
       " 'mixed_5d_branch5x5_2_conv': 44,\n",
       " 'mixed_5d_branch5x5_2_bn': 45,\n",
       " 'mixed_5d_branch3x3dbl_1_conv': 46,\n",
       " 'mixed_5d_branch3x3dbl_1_bn': 47,\n",
       " 'mixed_5d_branch3x3dbl_2_conv': 48,\n",
       " 'mixed_5d_branch3x3dbl_2_bn': 49,\n",
       " 'mixed_5d_branch3x3dbl_3_conv': 50,\n",
       " 'mixed_5d_branch3x3dbl_3_bn': 51,\n",
       " 'mixed_5d_branch_pool_conv': 52,\n",
       " 'mixed_5d_branch_pool_bn': 53,\n",
       " 'mixed_6a_branch3x3_conv': 54,\n",
       " 'mixed_6a_branch3x3_bn': 55,\n",
       " 'mixed_6a_branch3x3dbl_1_conv': 56,\n",
       " 'mixed_6a_branch3x3dbl_1_bn': 57,\n",
       " 'mixed_6a_branch3x3dbl_2_conv': 58,\n",
       " 'mixed_6a_branch3x3dbl_2_bn': 59,\n",
       " 'mixed_6a_branch3x3dbl_3_conv': 60,\n",
       " 'mixed_6a_branch3x3dbl_3_bn': 61,\n",
       " 'mixed_6b_branch1x1_conv': 62,\n",
       " 'mixed_6b_branch1x1_bn': 63,\n",
       " 'mixed_6b_branch7x7_1_conv': 64,\n",
       " 'mixed_6b_branch7x7_1_bn': 65,\n",
       " 'mixed_6b_branch7x7_2_conv': 66,\n",
       " 'mixed_6b_branch7x7_2_bn': 67,\n",
       " 'mixed_6b_branch7x7_3_conv': 68,\n",
       " 'mixed_6b_branch7x7_3_bn': 69,\n",
       " 'mixed_6b_branch7x7dbl_1_conv': 70,\n",
       " 'mixed_6b_branch7x7dbl_1_bn': 71,\n",
       " 'mixed_6b_branch7x7dbl_2_conv': 72,\n",
       " 'mixed_6b_branch7x7dbl_2_bn': 73,\n",
       " 'mixed_6b_branch7x7dbl_3_conv': 74,\n",
       " 'mixed_6b_branch7x7dbl_3_bn': 75,\n",
       " 'mixed_6b_branch7x7dbl_4_conv': 76,\n",
       " 'mixed_6b_branch7x7dbl_4_bn': 77,\n",
       " 'mixed_6b_branch7x7dbl_5_conv': 78,\n",
       " 'mixed_6b_branch7x7dbl_5_bn': 79,\n",
       " 'mixed_6b_branch_pool_conv': 80,\n",
       " 'mixed_6b_branch_pool_bn': 81,\n",
       " 'mixed_6c_branch1x1_conv': 82,\n",
       " 'mixed_6c_branch1x1_bn': 83,\n",
       " 'mixed_6c_branch7x7_1_conv': 84,\n",
       " 'mixed_6c_branch7x7_1_bn': 85,\n",
       " 'mixed_6c_branch7x7_2_conv': 86,\n",
       " 'mixed_6c_branch7x7_2_bn': 87,\n",
       " 'mixed_6c_branch7x7_3_conv': 88,\n",
       " 'mixed_6c_branch7x7_3_bn': 89,\n",
       " 'mixed_6c_branch7x7dbl_1_conv': 90,\n",
       " 'mixed_6c_branch7x7dbl_1_bn': 91,\n",
       " 'mixed_6c_branch7x7dbl_2_conv': 92,\n",
       " 'mixed_6c_branch7x7dbl_2_bn': 93,\n",
       " 'mixed_6c_branch7x7dbl_3_conv': 94,\n",
       " 'mixed_6c_branch7x7dbl_3_bn': 95,\n",
       " 'mixed_6c_branch7x7dbl_4_conv': 96,\n",
       " 'mixed_6c_branch7x7dbl_4_bn': 97,\n",
       " 'mixed_6c_branch7x7dbl_5_conv': 98,\n",
       " 'mixed_6c_branch7x7dbl_5_bn': 99,\n",
       " 'mixed_6c_branch_pool_conv': 100,\n",
       " 'mixed_6c_branch_pool_bn': 101,\n",
       " 'mixed_6d_branch1x1_conv': 102,\n",
       " 'mixed_6d_branch1x1_bn': 103,\n",
       " 'mixed_6d_branch7x7_1_conv': 104,\n",
       " 'mixed_6d_branch7x7_1_bn': 105,\n",
       " 'mixed_6d_branch7x7_2_conv': 106,\n",
       " 'mixed_6d_branch7x7_2_bn': 107,\n",
       " 'mixed_6d_branch7x7_3_conv': 108,\n",
       " 'mixed_6d_branch7x7_3_bn': 109,\n",
       " 'mixed_6d_branch7x7dbl_1_conv': 110,\n",
       " 'mixed_6d_branch7x7dbl_1_bn': 111,\n",
       " 'mixed_6d_branch7x7dbl_2_conv': 112,\n",
       " 'mixed_6d_branch7x7dbl_2_bn': 113,\n",
       " 'mixed_6d_branch7x7dbl_3_conv': 114,\n",
       " 'mixed_6d_branch7x7dbl_3_bn': 115,\n",
       " 'mixed_6d_branch7x7dbl_4_conv': 116,\n",
       " 'mixed_6d_branch7x7dbl_4_bn': 117,\n",
       " 'mixed_6d_branch7x7dbl_5_conv': 118,\n",
       " 'mixed_6d_branch7x7dbl_5_bn': 119,\n",
       " 'mixed_6d_branch_pool_conv': 120,\n",
       " 'mixed_6d_branch_pool_bn': 121,\n",
       " 'mixed_6e_branch1x1_conv': 122,\n",
       " 'mixed_6e_branch1x1_bn': 123,\n",
       " 'mixed_6e_branch7x7_1_conv': 124,\n",
       " 'mixed_6e_branch7x7_1_bn': 125,\n",
       " 'mixed_6e_branch7x7_2_conv': 126,\n",
       " 'mixed_6e_branch7x7_2_bn': 127,\n",
       " 'mixed_6e_branch7x7_3_conv': 128,\n",
       " 'mixed_6e_branch7x7_3_bn': 129,\n",
       " 'mixed_6e_branch7x7dbl_1_conv': 130,\n",
       " 'mixed_6e_branch7x7dbl_1_bn': 131,\n",
       " 'mixed_6e_branch7x7dbl_2_conv': 132,\n",
       " 'mixed_6e_branch7x7dbl_2_bn': 133,\n",
       " 'mixed_6e_branch7x7dbl_3_conv': 134,\n",
       " 'mixed_6e_branch7x7dbl_3_bn': 135,\n",
       " 'mixed_6e_branch7x7dbl_4_conv': 136,\n",
       " 'mixed_6e_branch7x7dbl_4_bn': 137,\n",
       " 'mixed_6e_branch7x7dbl_5_conv': 138,\n",
       " 'mixed_6e_branch7x7dbl_5_bn': 139,\n",
       " 'mixed_6e_branch_pool_conv': 140,\n",
       " 'mixed_6e_branch_pool_bn': 141,\n",
       " 'aux_logits_conv0_conv': 142,\n",
       " 'aux_logits_conv0_bn': 143,\n",
       " 'aux_logits_conv1_conv': 144,\n",
       " 'aux_logits_conv1_bn': 145,\n",
       " 'aux_logits_fc': 146,\n",
       " 'mixed_7a_branch3x3_1_conv': 147,\n",
       " 'mixed_7a_branch3x3_1_bn': 148,\n",
       " 'mixed_7a_branch3x3_2_conv': 149,\n",
       " 'mixed_7a_branch3x3_2_bn': 150,\n",
       " 'mixed_7a_branch7x7x3_1_conv': 151,\n",
       " 'mixed_7a_branch7x7x3_1_bn': 152,\n",
       " 'mixed_7a_branch7x7x3_2_conv': 153,\n",
       " 'mixed_7a_branch7x7x3_2_bn': 154,\n",
       " 'mixed_7a_branch7x7x3_3_conv': 155,\n",
       " 'mixed_7a_branch7x7x3_3_bn': 156,\n",
       " 'mixed_7a_branch7x7x3_4_conv': 157,\n",
       " 'mixed_7a_branch7x7x3_4_bn': 158,\n",
       " 'mixed_7b_branch1x1_conv': 159,\n",
       " 'mixed_7b_branch1x1_bn': 160,\n",
       " 'mixed_7b_branch3x3_1_conv': 161,\n",
       " 'mixed_7b_branch3x3_1_bn': 162,\n",
       " 'mixed_7b_branch3x3_2a_conv': 163,\n",
       " 'mixed_7b_branch3x3_2a_bn': 164,\n",
       " 'mixed_7b_branch3x3_2b_conv': 165,\n",
       " 'mixed_7b_branch3x3_2b_bn': 166,\n",
       " 'mixed_7b_branch3x3dbl_1_conv': 167,\n",
       " 'mixed_7b_branch3x3dbl_1_bn': 168,\n",
       " 'mixed_7b_branch3x3dbl_2_conv': 169,\n",
       " 'mixed_7b_branch3x3dbl_2_bn': 170,\n",
       " 'mixed_7b_branch3x3dbl_3a_conv': 171,\n",
       " 'mixed_7b_branch3x3dbl_3a_bn': 172,\n",
       " 'mixed_7b_branch3x3dbl_3b_conv': 173,\n",
       " 'mixed_7b_branch3x3dbl_3b_bn': 174,\n",
       " 'mixed_7b_branch_pool_conv': 175,\n",
       " 'mixed_7b_branch_pool_bn': 176,\n",
       " 'mixed_7c_branch1x1_conv': 177,\n",
       " 'mixed_7c_branch1x1_bn': 178,\n",
       " 'mixed_7c_branch3x3_1_conv': 179,\n",
       " 'mixed_7c_branch3x3_1_bn': 180,\n",
       " 'mixed_7c_branch3x3_2a_conv': 181,\n",
       " 'mixed_7c_branch3x3_2a_bn': 182,\n",
       " 'mixed_7c_branch3x3_2b_conv': 183,\n",
       " 'mixed_7c_branch3x3_2b_bn': 184,\n",
       " 'mixed_7c_branch3x3dbl_1_conv': 185,\n",
       " 'mixed_7c_branch3x3dbl_1_bn': 186,\n",
       " 'mixed_7c_branch3x3dbl_2_conv': 187,\n",
       " 'mixed_7c_branch3x3dbl_2_bn': 188,\n",
       " 'mixed_7c_branch3x3dbl_3a_conv': 189,\n",
       " 'mixed_7c_branch3x3dbl_3a_bn': 190,\n",
       " 'mixed_7c_branch3x3dbl_3b_conv': 191,\n",
       " 'mixed_7c_branch3x3dbl_3b_bn': 192,\n",
       " 'mixed_7c_branch_pool_conv': 193,\n",
       " 'mixed_7c_branch_pool_bn': 194,\n",
       " 'avgpool': 195,\n",
       " 'dropout': 196,\n",
       " 'fc': 197}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_graph.gammas_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34d9e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionOutputs(logits=tensor([[ 0.2396,  0.4675,  0.6938,  ...,  0.5704,  1.0240,  0.3124],\n",
       "        [-0.9802, -0.3262, -1.2678,  ..., -0.2163, -0.5276,  0.8134],\n",
       "        [ 0.6286, -0.3925,  0.7923,  ..., -0.7243, -0.2120, -0.9829]],\n",
       "       grad_fn=<MulBackward0>), aux_logits=tensor([[-1.7601,  0.7197,  0.0937,  ..., -1.5120,  1.0705,  0.1076],\n",
       "        [ 1.0559,  0.6736, -1.2077,  ...,  0.0332,  1.0180,  0.7502],\n",
       "        [ 0.3578, -1.5966,  1.2425,  ...,  0.7635, -1.6698, -0.5169]],\n",
       "       grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_graph(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b327cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "WORK_DIR = './data'\n",
    "BATCH_SIZE = 12\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "dataset = datasets.FakeData(24, (3, 400, 400), 2, transform=preprocess)\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                             batch_size= BATCH_SIZE,\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3fcd128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  0\n",
      "Step [12/120], Loss: 11.06143951.\n",
      "Running Loss= 132.73727416992188\n",
      "Acc: 0.0000.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  0\n",
      "Step [24/120], Loss: 9.68844223.\n",
      "Running Loss= 116.26130676269531\n",
      "Acc: 0.0417.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  1\n",
      "Step [36/120], Loss: 6.87118244.\n",
      "Running Loss= 82.45418930053711\n",
      "Acc: 0.1667.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  1\n",
      "Step [48/120], Loss: 4.87286329.\n",
      "Running Loss= 58.4743595123291\n",
      "Acc: 0.4167.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  2\n",
      "Step [60/120], Loss: 3.70966291.\n",
      "Running Loss= 44.51595497131348\n",
      "Acc: 1.0000.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  2\n",
      "Step [72/120], Loss: 1.97249496.\n",
      "Running Loss= 23.669939517974854\n",
      "Acc: 0.9583.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  3\n",
      "Step [84/120], Loss: 1.12656462.\n",
      "Running Loss= 13.518775463104248\n",
      "Acc: 1.0000.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  3\n",
      "Step [96/120], Loss: 0.53211695.\n",
      "Running Loss= 6.385403394699097\n",
      "Acc: 1.0000.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  4\n",
      "Step [108/120], Loss: 0.33935088.\n",
      "Running Loss= 4.0722105503082275\n",
      "Acc: 1.0000.\n",
      "torch.Size([12, 3, 299, 299])\n",
      "epoch:  4\n",
      "Step [120/120], Loss: 0.42928600.\n",
      "Running Loss= 5.151432037353516\n",
      "Acc: 1.0000.\n"
     ]
    }
   ],
   "source": [
    "gamma_graph = GraphInterperterWithGamma(traced_graph).to('cpu')\n",
    "device = \"cuda:0\"\n",
    "optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=0.01,\n",
    "        momentum=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "gamma_graph = gamma_graph.to(device)\n",
    "step = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    gamma_graph.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        gamma_graph.gammas.copy_(torch.bernoulli(gamma_graph.gammas))\n",
    "    \n",
    "    for images, labels in dataset_loader:\n",
    "          step += 1\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          print(images.shape)\n",
    "          outputs, aux_outputs = gamma_graph(images)\n",
    "          loss1 = criterion(outputs, labels)\n",
    "          loss2 = criterion(aux_outputs, labels)\n",
    "          loss = loss1 + 0.4*loss2\n",
    "          running_loss =+ loss.item() * images.size(0)\n",
    "        \n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          print(\"epoch: \", epoch)\n",
    "          print(f\"Step [{step * BATCH_SIZE}/{NUM_EPOCHS * len(dataset)}], \"\n",
    "            f\"Loss: {loss.item():.8f}.\")\n",
    "          print(\"Running Loss=\",running_loss)\n",
    "    \n",
    "          # equal prediction and acc\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          # val_loader total\n",
    "          total += labels.size(0)\n",
    "          # add correct\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "          print(f\"Acc: {correct / total:.4f}.\")\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d34dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
