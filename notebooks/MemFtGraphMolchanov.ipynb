{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9879be41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.module2graph import GraphInterperterWithGamma\n",
    "from src.resnet18 import ResNet18\n",
    "import numpy as np\n",
    "\n",
    "import graphviz\n",
    "import itertools\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, Dict # actually we don't need it for py>=3.9, but I have 3.8 on my laptop\n",
    "from src.utils import train_loop, test_loop\n",
    "#from numba import njit\n",
    "from src.cifar_data import get_dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc3e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward for target model with gamma values for each edge.\n",
    "# means - mean values for arguments\n",
    "def forward_with_gammas(model, gammas: Dict[Tuple[str, str], torch.Tensor], \n",
    "                        means: Dict[str, torch.Tensor] = None, *torch_model_args):\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "            gammas_node = [(gammas[e])  if (e is not None) else 1 for e in edges ]\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g  for a0,a,g in zip(node.args,\n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            #print (len(args), len(node.args))\n",
    "            #print (node, [a for a in node.args])\n",
    "            #print (node, [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            args =  [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args[1:], \n",
    "                                                                        args, gammas_node)]\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args, \n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            \n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "        \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return result, env # currently ignorign means for output\n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return result\n",
    "\n",
    "# a wrapper that takes model and uses forward_with_Gammas\n",
    "class PrunedModel(torch.nn.Module):\n",
    "    def __init__(self, base, prune_dict, means = None):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.prune_dict = prune_dict\n",
    "        self.means = means \n",
    "    def forward(self, x):\n",
    "        return forward_with_gammas(self.base, self.prune_dict,  self.means, x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22897ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets intermediate representations of nodes\n",
    "def get_inter(model, *torch_model_args) -> dict:\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    inter = {}\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            \n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            #print (len(args), len(node.args))\n",
    "            #print ([a.shape for a in load_arg(node.args)], [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            \n",
    "            for a_, a in zip(node.args[1:], args):\n",
    "                inter[a_] = a\n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "    \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return inter \n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651c865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dl, test_dl = get_dataloaders([0,1,2,3,4,5,6,7], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb347af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_to_graph(m: torch.nn.Module):\n",
    "    graph = torch.fx.symbolic_trace(m).graph\n",
    "    named_dict = dict(m.named_modules())\n",
    "    edges = [] # (from, to)\n",
    "    weights = {'x': 0} # node: params\n",
    "    for node in graph.nodes:\n",
    "        # no placeholder and call_mathod\n",
    "        if node.op == 'call_module':\n",
    "            n_params = sum([p.numel() for p in named_dict[node.target].parameters()])\n",
    "            weights[node.name] = n_params\n",
    "            assert len(node.args) == 1\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "        elif node.op == 'call_function':\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "            weights[node.name] = 0\n",
    "        elif node.op == 'output':\n",
    "            try:\n",
    "                edges.append((node.args[0][0].name, node.name))\n",
    "            except:\n",
    "                edges.append((node.args[0].name, node.name))\n",
    "            weights['output'] = 0\n",
    "            \n",
    "    return edges, {'_'.join(k.split('.')): v for k, v in weights.items()}\n",
    "\n",
    "#forward_with_gammas(torch.fx.symbolic_trace(ResNet18()), {k: 1.0 for k in edges}, torch.randn(64, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab87901",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'module_to_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m edges, weights, a, b \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_to_graph\u001b[49m(ResNet18())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# edges, weights\u001b[39;00m\n\u001b[1;32m      3\u001b[0m edges[:\u001b[38;5;241m10\u001b[39m], \u001b[38;5;28mlist\u001b[39m(weights\u001b[38;5;241m.\u001b[39mitems())[:\u001b[38;5;241m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'module_to_graph' is not defined"
     ]
    }
   ],
   "source": [
    "edges, weights, a, b = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f5ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting subset to evaulate mean\n",
    "edges, weights = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]\n",
    "\n",
    "\n",
    "\n",
    "train_dl_limit, _ = get_dataloaders([0,1,2,3,4,5,6,7], train_limit=1024)# 256\n",
    "len(train_dl_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "82c6dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n"
     ]
    }
   ],
   "source": [
    "inter = {}\n",
    "inter_std = {}\n",
    "model = ResNet18(8)\n",
    "# модель лежит тут \n",
    "# https://github.com/bahleg/fast_nas_adapt/blob/main/cv_experiment/results/cifar_8_pretrain/model_last.ckpt\n",
    "model.load_state_dict(torch.load('../model_last.ckpt', map_location='cpu'))\n",
    "tr = torch.fx.symbolic_trace(model)\n",
    "elem_count = 0\n",
    "for x,_ in train_dl_limit:\n",
    "    elem_count += x.shape[0]\n",
    "    i_ = get_inter(tr, x)\n",
    "    for k in i_:\n",
    "        try:\n",
    "            if str(k) not in inter:\n",
    "                inter[str(k)] = i_[k].sum(0).detach()\n",
    "                inter_std[str(k)] = [i_[k].detach()]\n",
    "            else:\n",
    "                inter[str(k)] += i_[k].sum(0).detach()\n",
    "                inter_std[str(k)].append(i_[k].detach())\n",
    "        except:\n",
    "            print ('bad inter', k) # промежуточное значение для константы\n",
    "        \n",
    "            #inter[str(k)] = 0.0\n",
    "for k in inter:\n",
    "    inter[k] /= elem_count\n",
    "for k in inter_std:\n",
    "    inter_std[k] = torch.cat(inter_std[k], dim=0).std(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17599e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac652fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab3e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951122a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c69fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253dae6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ba0fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# getting grads\n",
    "gammas = [torch.nn.Parameter(torch.tensor(1.0)) for k in edges]\n",
    "grads = [torch.tensor(0.0) for k in edges]\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('../model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "wrapped = torch.fx.symbolic_trace(model)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "pruned = PrunedModel(wrapped, {k:g for k,g in zip(edges, gammas)}, inter)\n",
    "\n",
    "for x,y in train_dl_limit:\n",
    "    loss = crit(pruned(x)[0], y)\n",
    "    gr = torch.autograd.grad(loss, gammas, allow_unused=True)\n",
    "    for i in range(len(gr)):\n",
    "        if gr[i] is not None and gr[i] == gr[i]:\n",
    "            grads[i] += gr[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0208fcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(581.3264),\n",
       " {('x', 'model_conv1'): tensor(0.7817),\n",
       "  ('model_conv1', 'model_bn1'): tensor(0.6577),\n",
       "  ('model_bn1', 'model_relu'): tensor(0.3459),\n",
       "  ('model_relu', 'model_maxpool'): tensor(0.4433),\n",
       "  ('model_maxpool', 'model_layer1_0_conv1'): tensor(0.0293),\n",
       "  ('model_layer1_0_conv1', 'model_layer1_0_bn1'): tensor(0.0677),\n",
       "  ('model_layer1_0_bn1', 'model_layer1_0_relu'): tensor(3.2715e-05),\n",
       "  ('model_layer1_0_relu', 'model_layer1_0_conv2'): tensor(0.0027),\n",
       "  ('model_layer1_0_conv2', 'model_layer1_0_bn2'): tensor(0.0041),\n",
       "  ('model_layer1_0_bn2', 'add'): tensor(0.2300),\n",
       "  ('model_maxpool', 'add'): tensor(1.4507),\n",
       "  ('add', 'model_layer1_0_relu_1'): tensor(0.4998),\n",
       "  ('model_layer1_0_relu_1', 'model_layer1_1_conv1'): tensor(0.0578),\n",
       "  ('model_layer1_1_conv1', 'model_layer1_1_bn1'): tensor(0.0678),\n",
       "  ('model_layer1_1_bn1', 'model_layer1_1_relu'): tensor(2.4827e-05),\n",
       "  ('model_layer1_1_relu', 'model_layer1_1_conv2'): tensor(0.0016),\n",
       "  ('model_layer1_1_conv2', 'model_layer1_1_bn2'): tensor(0.0014),\n",
       "  ('model_layer1_1_bn2', 'add_1'): tensor(0.0677),\n",
       "  ('model_layer1_0_relu_1', 'add_1'): tensor(0.1522),\n",
       "  ('add_1', 'model_layer1_1_relu_1'): tensor(0.0102),\n",
       "  ('model_layer1_1_relu_1', 'model_layer2_0_conv1'): tensor(0.4446),\n",
       "  ('model_layer2_0_conv1', 'model_layer2_0_bn1'): tensor(0.5053),\n",
       "  ('model_layer2_0_bn1', 'model_layer2_0_relu'): tensor(0.0008),\n",
       "  ('model_layer2_0_relu', 'model_layer2_0_conv2'): tensor(0.0130),\n",
       "  ('model_layer2_0_conv2', 'model_layer2_0_bn2'): tensor(0.0180),\n",
       "  ('model_layer1_1_relu_1', 'model_layer2_0_downsample_0'): tensor(0.1014),\n",
       "  ('model_layer2_0_downsample_0',\n",
       "   'model_layer2_0_downsample_1'): tensor(0.0270),\n",
       "  ('model_layer2_0_bn2', 'add_2'): tensor(0.6403),\n",
       "  ('model_layer2_0_downsample_1', 'add_2'): tensor(0.0123),\n",
       "  ('add_2', 'model_layer2_0_relu_1'): tensor(0.0007),\n",
       "  ('model_layer2_0_relu_1', 'model_layer2_1_conv1'): tensor(0.0254),\n",
       "  ('model_layer2_1_conv1', 'model_layer2_1_bn1'): tensor(0.0194),\n",
       "  ('model_layer2_1_bn1', 'model_layer2_1_relu'): tensor(0.0002),\n",
       "  ('model_layer2_1_relu', 'model_layer2_1_conv2'): tensor(0.0007),\n",
       "  ('model_layer2_1_conv2', 'model_layer2_1_bn2'): tensor(0.0004),\n",
       "  ('model_layer2_1_bn2', 'add_3'): tensor(0.0052),\n",
       "  ('model_layer2_0_relu_1', 'add_3'): tensor(0.0013),\n",
       "  ('add_3', 'model_layer2_1_relu_1'): tensor(1.5589e-05),\n",
       "  ('model_layer2_1_relu_1', 'model_layer3_0_conv1'): tensor(0.0039),\n",
       "  ('model_layer3_0_conv1', 'model_layer3_0_bn1'): tensor(0.0022),\n",
       "  ('model_layer3_0_bn1', 'model_layer3_0_relu'): tensor(0.0005),\n",
       "  ('model_layer3_0_relu', 'model_layer3_0_conv2'): tensor(1.4356e-05),\n",
       "  ('model_layer3_0_conv2', 'model_layer3_0_bn2'): tensor(8.3493e-06),\n",
       "  ('model_layer2_1_relu_1', 'model_layer3_0_downsample_0'): tensor(0.0027),\n",
       "  ('model_layer3_0_downsample_0',\n",
       "   'model_layer3_0_downsample_1'): tensor(0.0003),\n",
       "  ('model_layer3_0_bn2', 'add_4'): tensor(0.0127),\n",
       "  ('model_layer3_0_downsample_1', 'add_4'): tensor(0.5467),\n",
       "  ('add_4', 'model_layer3_0_relu_1'): tensor(0.0684),\n",
       "  ('model_layer3_0_relu_1', 'model_layer3_1_conv1'): tensor(0.0051),\n",
       "  ('model_layer3_1_conv1', 'model_layer3_1_bn1'): tensor(0.0018),\n",
       "  ('model_layer3_1_bn1', 'model_layer3_1_relu'): tensor(0.0001),\n",
       "  ('model_layer3_1_relu', 'model_layer3_1_conv2'): tensor(0.0016),\n",
       "  ('model_layer3_1_conv2', 'model_layer3_1_bn2'): tensor(0.0005),\n",
       "  ('model_layer3_1_bn2', 'add_5'): tensor(0.1085),\n",
       "  ('model_layer3_0_relu_1', 'add_5'): tensor(0.0991),\n",
       "  ('add_5', 'model_layer3_1_relu_1'): tensor(0.0020),\n",
       "  ('model_layer3_1_relu_1', 'model_layer4_0_conv1'): tensor(0.0006),\n",
       "  ('model_layer4_0_conv1', 'model_layer4_0_bn1'): tensor(3.9321e-05),\n",
       "  ('model_layer4_0_bn1', 'model_layer4_0_relu'): tensor(0.0012),\n",
       "  ('model_layer4_0_relu', 'model_layer4_0_conv2'): tensor(0.0008),\n",
       "  ('model_layer4_0_conv2', 'model_layer4_0_bn2'): tensor(0.0002),\n",
       "  ('model_layer3_1_relu_1', 'model_layer4_0_downsample_0'): tensor(0.0038),\n",
       "  ('model_layer4_0_downsample_0',\n",
       "   'model_layer4_0_downsample_1'): tensor(0.0002),\n",
       "  ('model_layer4_0_bn2', 'add_6'): tensor(2.8630),\n",
       "  ('model_layer4_0_downsample_1', 'add_6'): tensor(2.0253),\n",
       "  ('add_6', 'model_layer4_0_relu_1'): tensor(21.5190),\n",
       "  ('model_layer4_0_relu_1', 'model_layer4_1_conv1'): tensor(1.0347e-05),\n",
       "  ('model_layer4_1_conv1', 'model_layer4_1_bn1'): tensor(2.8092e-06),\n",
       "  ('model_layer4_1_bn1', 'model_layer4_1_relu'): tensor(0.0003),\n",
       "  ('model_layer4_1_relu', 'model_layer4_1_conv2'): tensor(0.0004),\n",
       "  ('model_layer4_1_conv2', 'model_layer4_1_bn2'): tensor(0.0001),\n",
       "  ('model_layer4_1_bn2', 'add_7'): tensor(3.2536),\n",
       "  ('model_layer4_0_relu_1', 'add_7'): tensor(17.7866),\n",
       "  ('add_7', 'model_layer4_1_relu_1'): tensor(109.9448),\n",
       "  ('model_layer4_1_relu_1', 'model_avgpool'): tensor(140.8340),\n",
       "  ('model_avgpool', 'flatten'): tensor(137.7743),\n",
       "  ('flatten', 'model_fc'): tensor(137.7743),\n",
       "  ('model_fc', 'output'): tensor(0.)})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c201c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ce7e9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inter_std['model_fc'] = torch.ones(1)\n",
    "\n",
    "inter_std['output'] = torch.ones(1)\n",
    "grads_sq = {e:g**2  for e,g in zip(edges, grads)}\n",
    "#sum(grads_sq.values()), grads_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8dc56d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0004),\n",
       " tensor(0.0022),\n",
       " tensor(0.0568),\n",
       " tensor(0.0728),\n",
       " tensor(0.0007),\n",
       " tensor(0.0007),\n",
       " tensor(5.2817e-06),\n",
       " tensor(0.0004),\n",
       " tensor(0.0004),\n",
       " tensor(0.0103),\n",
       " tensor(0.0330),\n",
       " tensor(0.0104),\n",
       " tensor(0.0012),\n",
       " tensor(0.0012),\n",
       " tensor(7.4199e-06),\n",
       " tensor(0.0005),\n",
       " tensor(0.0005),\n",
       " tensor(0.0055),\n",
       " tensor(0.0032),\n",
       " tensor(0.0002),\n",
       " tensor(0.0093),\n",
       " tensor(0.0057),\n",
       " tensor(0.0001),\n",
       " tensor(0.0020),\n",
       " tensor(0.0020),\n",
       " tensor(0.0021),\n",
       " tensor(0.0013),\n",
       " tensor(0.0136),\n",
       " tensor(0.0003),\n",
       " tensor(2.5643e-05),\n",
       " tensor(0.0010),\n",
       " tensor(0.0010),\n",
       " tensor(6.2668e-05),\n",
       " tensor(0.0003),\n",
       " tensor(0.0003),\n",
       " tensor(0.0005),\n",
       " tensor(5.2240e-05),\n",
       " tensor(7.0374e-07),\n",
       " tensor(0.0002),\n",
       " tensor(0.0001),\n",
       " tensor(0.0001),\n",
       " tensor(3.1153e-06),\n",
       " tensor(3.1154e-06),\n",
       " tensor(0.0001),\n",
       " tensor(8.6643e-05),\n",
       " tensor(0.0005),\n",
       " tensor(0.0279),\n",
       " tensor(0.0081),\n",
       " tensor(0.0006),\n",
       " tensor(0.0006),\n",
       " tensor(4.2484e-05),\n",
       " tensor(0.0007),\n",
       " tensor(0.0007),\n",
       " tensor(0.0167),\n",
       " tensor(0.0117),\n",
       " tensor(0.0002),\n",
       " tensor(6.0992e-05),\n",
       " tensor(5.4215e-05),\n",
       " tensor(0.0006),\n",
       " tensor(0.0004),\n",
       " tensor(0.0004),\n",
       " tensor(0.0004),\n",
       " tensor(0.0003),\n",
       " tensor(0.1034),\n",
       " tensor(0.0710),\n",
       " tensor(0.3283),\n",
       " tensor(1.5786e-07),\n",
       " tensor(1.5786e-07),\n",
       " tensor(0.0001),\n",
       " tensor(0.0002),\n",
       " tensor(0.0002),\n",
       " tensor(0.1435),\n",
       " tensor(0.2714),\n",
       " tensor(0.7807),\n",
       " tensor(1.),\n",
       " tensor(0.2500),\n",
       " tensor(0.2500),\n",
       " tensor(1.)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't process logit edge, so setting its ll to min\n",
    "grads_sq[('model_fc', 'output')] = max(grads_sq.values())\n",
    "edges_importance = [grads_sq[e]/max(grads_sq.values()) for e in edges] #[1.0 - edge_ll[e]/max(edge_ll.values()) + EPS for e in edges]\n",
    "edges_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592e369",
   "metadata": {},
   "source": [
    "<!-- ### Conclusion\n",
    "\n",
    "It seems that the problem is NP-hard. We need to come up with a new approach.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9a975",
   "metadata": {},
   "source": [
    "<!-- # The second attempt\n",
    "\n",
    "Consider the following heuristic\n",
    "\n",
    "1. Top sort (v_i, v_j) => i < j\n",
    "\n",
    "2. for k in {n, ..., 1}\n",
    "\n",
    "Consider 2 cases:\n",
    "\n",
    "a) put v_k into the layer of its nearest child + prune some edges\n",
    "\n",
    "b) put vk into a new layer => \n",
    "\n",
    "Consider all subsets of outcoming edges. We instantly identify a layer given a subset. So, we aggregate this layer with the answer of the nearest child to v_k\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cac8f",
   "metadata": {},
   "source": [
    "## The second attempt + deleting of edges\n",
    "\n",
    "1. Find all (sample) topological sorts\n",
    "\n",
    "https://www.geeksforgeeks.org/all-topological-sorts-of-a-directed-acyclic-graph/\n",
    "\n",
    "2. Apply greedy dynamic programming to find a monotonous solution\n",
    "\n",
    "3. Postprocess a graph: remove all nodes that are unreacheble from \"x\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f23f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legin/.local/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "DG = nx.DiGraph(edges)\n",
    "all_sorts = list(nx.all_topological_sorts(DG))\n",
    "len(all_sorts)\n",
    "rs = np.random.RandomState(42)\n",
    "rs.shuffle(all_sorts)\n",
    "all_sorts = all_sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68ea91bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 78)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges), len(edges_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1813ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def dp_for_top_sort(edges, weights, e_importance, top_sort_str, memory=1e10):\n",
    "    node_ids = {k: i for i, k in enumerate(weights)}\n",
    "    id_to_node = [node for _, node in enumerate(weights)]\n",
    "    top_sort = np.array([node_ids[n] for n in top_sort_str])\n",
    "    assert top_sort[-1] == node_ids['output']\n",
    "    assert top_sort[0] == node_ids['x']\n",
    "    assert top_sort.shape[0] == len(node_ids)\n",
    "    m = np.zeros((len(node_ids), len(node_ids))).astype(np.float32)\n",
    "    id_to_weight = np.array([weights[n] for n in id_to_node])\n",
    "    assert len(edges) == len(e_importance)\n",
    "    \n",
    "    for (src, dst), w in zip(edges, e_importance):\n",
    "        src_id, dst_id = node_ids[src], node_ids[dst]\n",
    "        m[src_id, dst_id] = w\n",
    "        \n",
    "    node_to_layers = np.ones((len(node_ids), len(node_ids))).astype(np.int32) * (-100)  # ans for each v ->\n",
    "    node_to_layers[top_sort[-1], top_sort[-1]] = 0\n",
    "    dp = [1e9] * len(node_ids)\n",
    "    dp[top_sort[-1]] = 0\n",
    "    for i in range(len(node_ids) - 2, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        for j in range(i, len(node_ids)):  # the last node of the first layer (starting from v)\n",
    "            if id_to_weight[top_sort[i: j + 1]].sum() > memory:\n",
    "                continue\n",
    "            if j == len(node_ids) - 1:\n",
    "                dp[v] = 0\n",
    "                node_to_layers[v, top_sort[i:]] = 0\n",
    "                continue\n",
    "            v_j = top_sort[j + 1]\n",
    "            next_layer_ids = [] if j + 1 >= len(node_ids) else \\\n",
    "            [k for k in range(m.shape[0]) if node_to_layers[v_j, k] == node_to_layers[v_j, v_j]]\n",
    "            pruned_value = sum([m[top_sort[k], l] for k in range(i, j + 1) for l in next_layer_ids if m[top_sort[k], l] != 0])\n",
    "            if dp[v_j] + pruned_value <= dp[v]:\n",
    "                dp[v] = dp[v_j] + pruned_value\n",
    "                node_to_layers[v] = node_to_layers[v_j]\n",
    "                node_to_layers[v, top_sort[i:j + 1]] = node_to_layers[v].max() + 1\n",
    "                \n",
    "    # prune restricted edges (TODO: also prune unreacheble nodes)\n",
    "    ans = node_to_layers[node_ids['x']]\n",
    "    pruned_edges_ids = [(i, j) for i in range(m.shape[0]) for j in range(m.shape[0]) \\\n",
    "                    if m[i, j] != 0 and abs(ans[i] - ans[j]) > 1]\n",
    "    pruned_edges = [(id_to_node[i], id_to_node[j]) for i, j in pruned_edges_ids]\n",
    "    pruned_value = sum([m[i, j] for i, j in pruned_edges_ids])\n",
    "    \n",
    "    # reach_ids = [set() for _ in range(len(node_ids))]\n",
    "    # for i in range(len(node_ids) - 1, -1, -1):\n",
    "    #     v = top_sort[i]\n",
    "    #     reach_ids[v].add(v)\n",
    "    #     for k in range(i + 1, m.shape[0]):\n",
    "    #         v_c = top_sort[k]\n",
    "    #         if m[v, v_c] != 0 and (v, v_c) not in pruned_edges_ids:\n",
    "    #             reach_ids[v] |= reach_ids[v_c]\n",
    "    # conn_g = top_sort[-1] in reach_ids[top_sort[0]]\n",
    "    conn_g = is_conn(m, node_ids['x'], node_ids['output'])\n",
    "    if pruned_value == 0:\n",
    "        assert conn_g\n",
    "                \n",
    "    return {'node_to_layer': {id_to_node[i]: ans.max() - l for i, l in enumerate(ans)},\n",
    "            'pruned_value': pruned_value, 'pruned_edges': pruned_edges,\n",
    "            'connected_graph': conn_g}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94affd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32632d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conn(m: np.ndarray, src: int, dst: int):\n",
    "    reach = [False] * m.shape[0]\n",
    "    reach[src] = True\n",
    "    for _ in range(m.shape[0]):\n",
    "        for i in range(m.shape[0]):\n",
    "            if reach[i] == False:\n",
    "                continue\n",
    "            for j in range(m.shape[0]):\n",
    "                if m[i, j] != 0:\n",
    "                    reach[j] = True\n",
    "    return reach[dst]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238b49e089ec49158641d4da262c71ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156407489e36427488bef1c3277453fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cb69ddd84c491ebe91768034f72e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c5cc942fd04f66982e2f23c517903d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9718c5b6a5d9404cbd67b9bd8cc88462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425073c1e7c7410db6abe0e06b225030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d9ac35968d43cfa808604476bf96f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b39671751614cbf97b0541ccda9a19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a79360dcce404dae3a917a15fcf13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae761a31a38c41149532cd24fe27b14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d531851d26943b8b0bbd9200130797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0cf3adb42d434aaefc8e098c1882b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65f91d8933947f3857258f570155690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4ac63849534d80b2a9d7c6b926d416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90644ae82cb44c58e1a942dd5dff01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### find the best solution\n",
    "import pickle\n",
    "POW = 1.0\n",
    "\n",
    "eval_dict = {}\n",
    "fine_dict = {}\n",
    "\n",
    "for edge_mem in range(2,6):\n",
    "    if edge_mem in eval_dict and edge_mem in fine_dict:\n",
    "        print ('skip', edge_mem)\n",
    "        continue\n",
    " \n",
    "    model = ResNet18(8)\n",
    "    model.load_state_dict(torch.load('../model_last.ckpt', map_location='cpu'))\n",
    "    warp = GraphInterperterWithGamma(model)\n",
    "\n",
    "    named_dict = dict(model.named_modules())\n",
    "\n",
    "    edges, weights = module_to_graph(ResNet18())\n",
    "    # edges, weights\n",
    "    edges[:10], list(weights.items())[:10]\n",
    "    \n",
    "    best_pruned = 1e10\n",
    "    best_val = None\n",
    "    for s in tqdm(all_sorts):\n",
    "        # for mem=8 the computation takes time\n",
    "        res = dp_for_top_sort(edges, {k: 1 for k in weights}, [np.random.uniform() for _ in edges_importance]\n",
    "                                  , #[k.item()**POW for k in edges_importance],\n",
    "                                              s, edge_mem)  \n",
    "      \n",
    "        if res['connected_graph'] == True and best_pruned > res['pruned_value']:\n",
    "            best_pruned = res['pruned_value']\n",
    "            best_val = res\n",
    "\n",
    "        if best_pruned == 0:\n",
    "            print(res)\n",
    "            break\n",
    "\n",
    "\n",
    "    model = ResNet18(8)\n",
    "    model.load_state_dict(torch.load('../model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "    wrapped = torch.fx.symbolic_trace(model)\n",
    "    pruned = PrunedModel(wrapped, {k:1.0 if k not in best_val['pruned_edges'] else 0.0 for k in edges }, inter)\n",
    "\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "    if edge_mem not in eval_dict:\n",
    "        eval_dict[edge_mem] = []\n",
    "    eval_dict[edge_mem].append(res)\n",
    "\n",
    "    train_loop(pruned, train_dl, test_dl, 9999999999, 1, 1e-3,  \"cpu\")\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "    if edge_mem not in fine_dict:\n",
    "        fine_dict[edge_mem] = []\n",
    "    fine_dict[edge_mem].append(res)\n",
    "\n",
    "    import pickle\n",
    "    with open('molchanov.pckl', 'wb') as out:\n",
    "        out.write(pickle.dumps([eval_dict, fine_dict]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eac7f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125], 3: [0.125], 4: [0.125], 5: [0.21774999797344208]},\n",
       " {2: [0.125], 3: [0.125], 4: [0.6290000081062317], 5: [0.6866250038146973]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('molchanov.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361d4743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125], 3: [0.125], 4: [0.12600000202655792], 5: [0.2502500116825104]},\n",
       " {2: [0.5786250233650208],\n",
       "  3: [0.5649999976158142],\n",
       "  4: [0.6498749852180481],\n",
       "  5: [0.6822500228881836]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('naive_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74ea4825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.12962499260902405, 0.125, 0.125],\n",
       "  3: [0.125, 0.125, 0.125],\n",
       "  4: [0.12612499296665192, 0.12612499296665192, 0.125],\n",
       "  5: [0.12587499618530273, 0.12587499618530273, 0.12562499940395355]},\n",
       " {2: [0.5892500281333923, 0.5241249799728394, 0.6132500171661377],\n",
       "  3: [0.5706250071525574, 0.6041250228881836, 0.5644999742507935],\n",
       "  4: [0.6047499775886536, 0.6507499814033508, 0.6359999775886536],\n",
       "  5: [0.6508749723434448, 0.6942499876022339, 0.6966249942779541]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('random_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
