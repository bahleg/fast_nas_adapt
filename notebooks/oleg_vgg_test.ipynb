{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-lWeR8Zjlv0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fast_nas_adapt/fast_nas_adapt/\n"
      ],
      "metadata": {
        "id": "1r5atC7yloH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "ImLCoeWwJGFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b bahleg-experiments https://github.com/bahleg/fast_nas_adapt.git"
      ],
      "metadata": {
        "id": "hcRJ3Lynl-s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r fast_nas_adapt"
      ],
      "metadata": {
        "id": "0dupeofnmBtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git checkout bahleg-experiments"
      ],
      "metadata": {
        "id": "DzvzwbHBmXvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "TyQlSusaa3VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *pckl"
      ],
      "metadata": {
        "id": "y0GSaeVWaYA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./src/')\n",
        "import importlib\n",
        "from matplotlib import pylab as plt\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import cifar_data\n",
        "import utils #у меня есть utils библиотека, поэтому переименовала\n",
        "import dartslike\n",
        "import VGG19\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import gc\n",
        "import argparse\n",
        "import dartslike\n",
        "\n",
        "import importlib\n",
        "import module2graph2\n",
        "importlib.reload(module2graph2)\n",
        "from torch.fx import symbolic_trace\n"
      ],
      "metadata": {
        "id": "LpJ2lYO1aAi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def safe_prune(model, trainloader, num_to_prune, gammas_to_prune):\n",
        "    for x,y in trainloader:\n",
        "        break\n",
        "    num = 0\n",
        "    for g in gammas_to_prune:\n",
        "            model.gammas[g] = 1.0\n",
        "    \n",
        "    i = 0\n",
        "    while num < num_to_prune and i < len(gammas_to_prune):\n",
        "        model.gammas[i] = 0.0\n",
        "  \n",
        "        if abs(model(x) - model(torch.zeros(x.shape))).sum() < 1e-5:\n",
        "            model.gammas[i] = 1.0\n",
        "            i += 1\n",
        "        else:\n",
        "            num += 1\n",
        "            i += 1\n",
        "    if num == num_to_prune:\n",
        "        return True\n",
        "    else:\n",
        "        return False \n"
      ],
      "metadata": {
        "id": "H6v0MM-ya--g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LowRankLinear(torch.nn.Module):\n",
        "    def __init__(self, in_, out_, dim=1):\n",
        "        super().__init__()\n",
        "        self.l = torch.nn.Parameter(torch.randn(in_, dim)*1e-3)\n",
        "        self.r = torch.nn.Parameter(torch.randn(dim, out_) * 1e-3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #print (x.shape, self.l.shape, self.r.shape)\n",
        "        return x@self.l@self.r\n",
        "\n",
        "\n",
        "class Aux(torch.nn.Module):\n",
        "    def __init__(self, sizes, layer_names):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        self.layer_names = layer_names\n",
        "        self.means_int = torch.nn.ModuleDict()\n",
        "        self.lsigmas_int = torch.nn.ParameterDict()\n",
        "        self.means_y = torch.nn.ModuleDict()\n",
        "        self.lsigmas_y = torch.nn.ParameterDict()\n",
        "        \n",
        "        for i in range(len(layer_names)-1):\n",
        "            current = layer_names[i]\n",
        "            next_ = layer_names[i+1]\n",
        "            mat_size = np.prod(sizes[current][1:]) * np.prod(sizes[next_][1:])\n",
        "            if mat_size > 1024 * 1024:\n",
        "                linear = LowRankLinear(np.prod(sizes[current][1:]), np.prod(sizes[next_][1:]))\n",
        "            else:\n",
        "                linear = torch.nn.Linear(np.prod(sizes[current][1:]), np.prod(sizes[next_][1:]))\n",
        "            \n",
        "            lsigma = torch.tensor(-2.0)\n",
        "            self.means_int.update({current: linear})\n",
        "            self.lsigmas_int.update({current: lsigma})\n",
        "            self.layers.append(linear)\n",
        "            \n",
        "        for i in range(len(layer_names)):\n",
        "            current = layer_names[i]\n",
        "            linear = torch.nn.Linear(np.prod(sizes[current][1:]), 2)\n",
        "            lsigma = torch.nn.Parameter(torch.tensor(-2.0))\n",
        "            self.means_y.update({current: linear})\n",
        "            self.lsigmas_y.update({current: lsigma})\n",
        "            self.layers.append(linear)\n",
        "            "
      ],
      "metadata": {
        "id": "Pzf79PBydORB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm *pckl"
      ],
      "metadata": {
        "id": "hU3tN49sdyEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for seed in [0, 13, 42]:\n",
        "    for parameter_opt_type in ['MI', 'CE']:\n",
        "        for gamma_opt_type in ['MI', 'CE']:\n",
        "            for lam in [0.0, 0.25, 0.5, 0.75, 1.0][::-1]:\n",
        "                if gamma_opt_type == 'CE' and parameter_opt_type == 'CE' and lam != 0:\n",
        "                    continue\n",
        "                name = f'{parameter_opt_type}.{gamma_opt_type}.{lam}.{seed}'\n",
        "                if os.path.exists(name+'.pckl'):\n",
        "                  continue\n",
        "                batch_size = 64\n",
        "                device = 'cuda:0'\n",
        "                trial_num = 1\n",
        "                epoch_num = 50\n",
        "                lr = 1e-3\n",
        "                wd = 1e-6\n",
        "                batch_seen = 5\n",
        "                trainloader, valloader, testloader = cifar_data.get_dataloaders([0,1], batch_size=batch_size, need_val=True, cifar100 = True)\n",
        "                model = VGG19.VGG19(num_classes = 10).to(device)\n",
        "                model.load_state_dict(torch.load('../VGG19_CIFAR10.ckpt', map_location=device))\n",
        "                model.model.classifier[6] = torch.nn.Linear(4096, 2)\n",
        "                traced_graph = symbolic_trace(model)\n",
        "                module2graph2.make_gamma_hooks(model, traced_graph, lambda: module2graph2.SigmoidGamma(0.0))\n",
        "                model.to(device)\n",
        "                sizes = {}\n",
        "                model(torch.randn(64, 3, 33, 33).to(device))\n",
        "                for k,v in model.intermediate.items():\n",
        "                    sizes[k] = v.shape\n",
        "                layer_names = [k for k in sizes]\n",
        "\n",
        "                \n",
        "                print (name)\n",
        "                torch.manual_seed(seed)\n",
        "                np.random.seed(seed)\n",
        "                def intermediate_getter(x):\n",
        "                    out = model(x)[0]\n",
        "                    inter = model.intermediate\n",
        "                    return out, inter \n",
        "                aux = Aux(sizes, layer_names).to(device)\n",
        "\n",
        "                dl = dartslike.DartsLikeTrainer(model, parameter_optimization=parameter_opt_type, gamma_optimization=gamma_opt_type,\n",
        "                                                    aux=aux,MI_Y_lambda=lam, layer_wise=False)\n",
        "            \n",
        "                history = dl.train_loop(trainloader, valloader, testloader, batch_seen, epoch_num, lr, lr, device, wd, model,\n",
        "                                        intermediate_getter = intermediate_getter)\n",
        "\n",
        "                with open(name+'.pckl','wb') as out:\n",
        "                    #out.write(pickle.dumps( (history, model.cpu().state_dict())))\n",
        "                    out.write(pickle.dumps( (history)))\n",
        "\n"
      ],
      "metadata": {
        "id": "RxPZ0g2AdRf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np \n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "plt.xlabel('gamma_optimization')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "for parameter_opt_type in ['MI', 'CE']:\n",
        "    for gamma_opt_type in ['MI', 'CE']:\n",
        "        for lam in [0.0, 0.25, 0.5, 0.75, 1.0][::-1]:\n",
        "          results = []\n",
        "          name = f'{parameter_opt_type}.{gamma_opt_type}.{lam}.{seed}'\n",
        "          if gamma_opt_type == 'CE' and parameter_opt_type == 'CE' and lam != 0:\n",
        "                continue\n",
        "\n",
        "          for seed in [0, 13, 42]:\n",
        "            \n",
        "            \n",
        "            with open(name+'.pckl', 'rb') as inp:\n",
        "              results.append(pickle.loads(inp.read()))\n",
        "          plt.plot(np.mean(results, 0))\n",
        "          plt.fill_between(list(range(len(results[0]))), np.mean(results, 0) - np.std(results, 0), np.mean(results, 0) + np.std(results, 0), label= f'{parameter_opt_type}.{gamma_opt_type}.{lam}', alpha=0.5)\n",
        "plt.legend(loc='best')\n",
        "            \n"
      ],
      "metadata": {
        "id": "Lz5oOmz_fX6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(results, 0)"
      ],
      "metadata": {
        "id": "M4SANnCwfydh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "w7FYdD9EgWVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sNHPBJv67lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgbZlu5qd-VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model(torch.randn(64, 3, 33, 33).to(device))"
      ],
      "metadata": {
        "id": "1TOdgDyQ3jAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLe_HA-b4Zz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LkQ706Ch36O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "LHb63YMfiwop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AueNV3xBbG_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for g in model.named_modules():\n",
        "  if 'gamma' in g[0].lower():\n",
        "    print (g[0], list(g[1].parameters()))"
      ],
      "metadata": {
        "id": "qnjGs4i87evA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.gammas)"
      ],
      "metadata": {
        "id": "Gd-o1-fj940r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for g in model.gammas:\n",
        "  print (g)"
      ],
      "metadata": {
        "id": "RIqD20WMhIMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}