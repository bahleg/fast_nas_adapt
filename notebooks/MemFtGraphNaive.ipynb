{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9879be41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.module2graph import GraphInterperterWithGamma\n",
    "from src.resnet18 import ResNet18\n",
    "import numpy as np\n",
    "\n",
    "import graphviz\n",
    "import itertools\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple, Dict # actually we don't need it for py>=3.9, but I have 3.8 on my laptop\n",
    "from src.utils import train_loop, test_loop\n",
    "#from numba import njit\n",
    "from src.cifar_data import get_dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc3e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward for target model with gamma values for each edge.\n",
    "# means - mean values for arguments\n",
    "def forward_with_gammas(model, gammas: Dict[Tuple[str, str], torch.Tensor], \n",
    "                        means: Dict[str, torch.Tensor] = None, *torch_model_args):\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "            gammas_node = [int(gammas[e])  if (e is not None) else 1 for e in edges ]\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g  for a0,a,g in zip(node.args,\n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            #print (len(args), len(node.args))\n",
    "            #print (node, [a for a in node.args])\n",
    "            #print (node, [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            args =  [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args[1:], \n",
    "                                                                        args, gammas_node)]\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args, \n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            \n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "            \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return result, env # currently ignorign means for output\n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return result\n",
    "\n",
    "# a wrapper that takes model and uses forward_with_Gammas\n",
    "class PrunedModel(torch.nn.Module):\n",
    "    def __init__(self, base, prune_dict, means = None):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.prune_dict = prune_dict\n",
    "        self.means = means \n",
    "    def forward(self, x):\n",
    "        return forward_with_gammas(self.base, self.prune_dict,  self.means, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22897ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets intermediate representations of nodes\n",
    "def get_inter(model, *torch_model_args) -> dict:\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    inter = {}\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            \n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            #print (len(args), len(node.args))\n",
    "            #print ([a.shape for a in load_arg(node.args)], [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            \n",
    "            for a_, a in zip(node.args[1:], args):\n",
    "                inter[a_] = a\n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "    \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return inter \n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651c865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dl, test_dl = get_dataloaders([0,1,2,3,4,5,6,7], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb347af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean \n",
    "\n",
    "def module_to_graph(m: torch.nn.Module):\n",
    "    graph = torch.fx.symbolic_trace(m).graph\n",
    "    named_dict = dict(m.named_modules())\n",
    "    edges = [] # (from, to)\n",
    "    grad = {'x': 0}\n",
    "    params = {'x': 0}\n",
    "    weights = {'x': 0} # node: params\n",
    "    means = {}\n",
    "    for node in graph.nodes:\n",
    "    \n",
    "        # no placeholder and call_mathod\n",
    "        if node.op == 'call_module':\n",
    "            n_params = 0\n",
    "            grad_1 = []\n",
    "            params_1 = []\n",
    "            for p in named_dict[node.target].parameters():\n",
    "                n_params += p.numel()\n",
    "                grad_1.append(p.grad)\n",
    "                params_1.append(p)\n",
    "            try:\n",
    "                grad[node.name] = torch.mean(torch.stack(grad_1))\n",
    "                params[node.name] = torch.mean(torch.stack(params_1))\n",
    "            except:\n",
    "                grad[node.name] = 0\n",
    "                params[node.name] = 0\n",
    "            weights[node.name] = n_params\n",
    "            assert len(node.args) == 1\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "        elif node.op == 'call_function':\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "            weights[node.name] = 0\n",
    "        elif node.op == 'output':\n",
    "            try:\n",
    "                edges.append((node.args[0][0].name, node.name))\n",
    "            except:\n",
    "                edges.append((node.args[0].name, node.name))\n",
    "            weights['output'] = 0\n",
    "        \n",
    "        #if  len(edges)>0 and edges[-1] == ('model_maxpool', 'add'):\n",
    "        #    print (node.args, node.name, node.op)\n",
    "    return edges, {'_'.join(k.split('.')): v for k, v in weights.items()}, {'_'.join(k.split('.')): v for k, v in params.items()}, {'_'.join(k.split('.')): v for k, v in grad.items()}\n",
    "\n",
    "module_to_graph(ResNet18())\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab87901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('x', 'model_conv1'),\n",
       "  ('model_conv1', 'model_bn1'),\n",
       "  ('model_bn1', 'model_relu'),\n",
       "  ('model_relu', 'model_maxpool'),\n",
       "  ('model_maxpool', 'model_layer1_0_conv1'),\n",
       "  ('model_layer1_0_conv1', 'model_layer1_0_bn1'),\n",
       "  ('model_layer1_0_bn1', 'model_layer1_0_relu'),\n",
       "  ('model_layer1_0_relu', 'model_layer1_0_conv2'),\n",
       "  ('model_layer1_0_conv2', 'model_layer1_0_bn2'),\n",
       "  ('model_layer1_0_bn2', 'add')],\n",
       " [('x', 0),\n",
       "  ('model_conv1', 9408),\n",
       "  ('model_bn1', 128),\n",
       "  ('model_relu', 0),\n",
       "  ('model_maxpool', 0),\n",
       "  ('model_layer1_0_conv1', 36864),\n",
       "  ('model_layer1_0_bn1', 128),\n",
       "  ('model_layer1_0_relu', 0),\n",
       "  ('model_layer1_0_conv2', 36864),\n",
       "  ('model_layer1_0_bn2', 128)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, weights, a, b = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7f5ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting subset to evaulate mean\n",
    "edges, weights, a, b = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]\n",
    "\n",
    "\n",
    "\n",
    "train_dl_limit, _ = get_dataloaders([0,1,2,3,4,5,6,7], train_limit=256)# 256\n",
    "len(train_dl_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c6dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n"
     ]
    }
   ],
   "source": [
    "inter = {}\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('../data/model_last.ckpt', map_location='cpu'))\n",
    "tr = torch.fx.symbolic_trace(model)\n",
    "elem_count = 0\n",
    "for x,_ in train_dl_limit:\n",
    "    elem_count += x.shape[0]\n",
    "    i_ = get_inter(tr, x)\n",
    "    for k in i_:\n",
    "        try:\n",
    "            if k not in inter:\n",
    "                inter[str(k)] = i_[k].sum(0).detach()\n",
    "            else:\n",
    "                inter[str(k)] += i_[k].sum(0).detach()\n",
    "        except:\n",
    "            print ('bad inter', k)\n",
    "            #inter[str(k)] = 0.0\n",
    "    for k in inter:\n",
    "        inter[k] /= elem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085d0e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70932072d2b437094a139d80360f627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.79296875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likelihood of the model without pruning\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('../data/model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "    \n",
    "# full_ll = test_loop(model, train_dl_limit, nc=8, return_ll=True, device='cpu')\n",
    "full_ll = test_loop(model, train_dl_limit, nc=8, return_ll=False, device='cpu')\n",
    "full_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e33480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a70b87e2d44088a7533da799911dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9306f8d7a03442528935927e7945b7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e520ac2dd7ab47fd8c2e401b14880c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af537d4626624c88b0c18371d623be85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb012fa4e924adfab4a41951c799e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e08fdd70004f42affeb884a6654336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b09a10143614d229bc0296653949143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8410627da5f2437a945999bbd8fcb879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f57aa8c8eb648409f00ad70ca796b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf03cff9a6f4fd3904f00620b271e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4cb805cb0c4c459bd500f6d9c3cbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c883a6a264d4ff497a20f9f87721849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70f31ca744a47fda56d58dfa21da1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34f28fc9dfa426ba634d4e6a2b1d834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd0bfdc9d46489ab95d6a8e830fa474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5031a481a1ab4cd69583c7a3eda04398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2757d465ea584faa8760c007921747ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaaeafd6d3ea4c6aa0539fb1a75bd4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e8277c75e34b08a74b3380aaeb257d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa8aca2ece74a21812c859a8d079598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd219316417840ef9ba2860dfc0e3047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5376ef065536489081d5508209a1a0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba438801b4624a158cd538a82b25890f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064cb0225d9b409b8f0ca07cb0bb82d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054db7e704ca4ccfa9df6b718a786d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95b4a69b1bc47d4b6aff1090ab4c85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381d46ce838b4c49aaf2df9ea30d5c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205d484fb90c455ca2d82142d381ed3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a980321e24f3437bbce7491a7329e85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94241f6dcb23428d91118023bbb88bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2418a1117294a798457466c243c7ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2547c59de5a04f3cb2bd0dc0677ee86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0189336d3504a06abc7076ded7f8d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8342c8dc969e4363ada71bdbd4c811db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf931cc2a2ce4faea758b6d5040f38f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f79cadfc6b497ba98be9d33cbb6382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f607a5262d424870ad6681bef2670624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684ea9e5000f44899a6f33c0c6e38cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b14d6ab7c94f7fb5ba7693f677be92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d752548bd04f00bdcc1f9310bf25a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e7b2c8f23a4ab98efc581873a98e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b5d76abf394343bef2edf3febbdc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71f2970bd0f4663a0109fe92789b961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caef9f7f423646188eeafa29c41bc198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46128ad64f894a5c87dff8c2f5a298bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768595e22b84475699c7e3ff4d855887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f10ad2c4b0c4bbe97675f798e1eb032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f515b12fe90493aad478cdb8ede7623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a673b8fb8ca841b2a264a898bed3fff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbd8f054fc24b0989b93d6437d38461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463a4d3fa4c34ff3b3e30a224a9c4e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f4be2cb1b049539f8b254590a8f877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4683d487585947249efa138104fc7d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0b812342ac49c9891a637e399f7aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c204cdf0d814bd0965a4add143aa12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a88a3d2b3243758cfc64391fc3cb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f15c378d774086b88711090a261315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8b77711e114deab913c55da25558a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7bb7b045aa4969868edebc597fb54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efa22c05ed940c387ca020f65d95ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483b1eff4832470e9b0f68618b972c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda46ed3edbc41848362dd8bf78e68cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90abf4f052c475f857023688cafb256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e063f22796c4df4b9881c4ddf8649fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2afcba6a3074ed9994ea9170c7f3bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c4af94ee604bd7829423c2352231ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cf3ad6811d4ff287aef8e6ed801d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af003de876754a77ac8c8f14d6792d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14806f9f50e841e983be8ab2b84bc606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd45dd4bdbaa442d9b48eb2fa942ad7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d28f20d39c646a2b7e408f338c7af2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d138542f7f142158fc19f2b1c00299a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9119856f3c5441cfb30f24ae6f4b0b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dc098b2382478082f683e24cd4d6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf99210c79ac4943b6c5b40c46d5c642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0c7af5b1f04034b84b713c4d25a93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195763904f434ca58a33c03c3a113f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72d2c9d5b744c81a286cf972f27484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d92131e8241f598830fd77395955d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ll for pruned models\n",
    "edge_ll = {}\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('../data/model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "wrapped = torch.fx.symbolic_trace(model)\n",
    "    \n",
    "    \n",
    "for e in tqdm(edges):\n",
    "    pruned = PrunedModel(wrapped, {k:1.0 if k != e else 0.0 for k in edges }, inter)\n",
    "    # edge_ll[e] = test_loop(pruned, train_dl_limit, nc=8, return_ll=True, device='cpu')\n",
    "    edge_ll[e] = test_loop(pruned, train_dl_limit, nc=8, return_ll=False, device='cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dc56d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.896551724137931,\n",
       " 0.896551724137931,\n",
       " 0.896551724137931,\n",
       " 0.896551724137931,\n",
       " 0.5862068965517241,\n",
       " 0.5862068965517241,\n",
       " 0.1280788177339901,\n",
       " 0.1280788177339901,\n",
       " 0.1280788177339901,\n",
       " 0.1428571428571428]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't process logit edge, so setting its ll to min\n",
    "edge_ll[('model_fc', 'output')] = max(edge_ll.values())\n",
    "# edges_importance = [edge_ll[e]/max(edge_ll.values()) for e in edges]\n",
    "edges_importance = [-edge_ll[e] / full_ll for e in edges]\n",
    "edges_importance = [imp - min(edges_importance) for imp in edges_importance]\n",
    "\n",
    "edges_importance[:10]\n",
    "# {e : -edge_ll[e] / full_ll for e in edges}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cac8f",
   "metadata": {},
   "source": [
    "## The second attempt + deleting of edges\n",
    "\n",
    "1. Find all (sample) topological sorts\n",
    "\n",
    "https://www.geeksforgeeks.org/all-topological-sorts-of-a-directed-acyclic-graph/\n",
    "\n",
    "2. Apply greedy dynamic programming to find a monotonous solution\n",
    "\n",
    "3. Postprocess a graph: remove all nodes that are unreacheble from \"x\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f23f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG = nx.DiGraph(edges)\n",
    "all_sorts = list(nx.all_topological_sorts(DG))\n",
    "len(all_sorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68ea91bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges), len(edges_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec1813ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def dp_for_top_sort(edges, weights, e_importance, top_sort_str, memory=1e10):\n",
    "    node_ids = {k: i for i, k in enumerate(weights)}\n",
    "    id_to_node = [node for _, node in enumerate(weights)]\n",
    "    top_sort = np.array([node_ids[n] for n in top_sort_str])\n",
    "    assert top_sort[-1] == node_ids['output']\n",
    "    assert top_sort[0] == node_ids['x']\n",
    "    assert top_sort.shape[0] == len(node_ids)\n",
    "    m = np.zeros((len(node_ids), len(node_ids))).astype(np.int32)\n",
    "    id_to_weight = np.array([weights[n] for n in id_to_node])\n",
    "    assert len(edges) == len(e_importance)\n",
    "    for (src, dst), w in zip(edges, e_importance):\n",
    "        src_id, dst_id = node_ids[src], node_ids[dst]\n",
    "        m[src_id, dst_id] = w\n",
    "        \n",
    "    node_to_layers = np.ones((len(node_ids), len(node_ids))).astype(np.int32) * (-100)  # ans for each v ->\n",
    "    node_to_layers[top_sort[-1], top_sort[-1]] = 0\n",
    "    dp = [1e9] * len(node_ids)\n",
    "    dp[top_sort[-1]] = 0\n",
    "    for i in range(len(node_ids) - 2, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        for j in range(i, len(node_ids)):  # the last node of the first layer (starting from v)\n",
    "            if id_to_weight[top_sort[i: j + 1]].sum() > memory:\n",
    "                continue\n",
    "            if j == len(node_ids) - 1:\n",
    "                dp[v] = 0\n",
    "                node_to_layers[v, top_sort[i:]] = 0\n",
    "                continue\n",
    "            v_j = top_sort[j + 1]\n",
    "            next_layer_ids = [] if j + 1 >= len(node_ids) else \\\n",
    "            [k for k in range(m.shape[0]) if node_to_layers[v_j, k] == node_to_layers[v_j, v_j]]\n",
    "            pruned_value = sum([m[top_sort[k], l] for k in range(i, j + 1) for l in next_layer_ids if m[top_sort[k], l] != 0])\n",
    "            if dp[v_j] + pruned_value <= dp[v]:\n",
    "                dp[v] = dp[v_j] + pruned_value\n",
    "                node_to_layers[v] = node_to_layers[v_j]\n",
    "                node_to_layers[v, top_sort[i:j + 1]] = node_to_layers[v].max() + 1\n",
    "                \n",
    "    # prune restricted edges (TODO: also prune unreacheble nodes)\n",
    "    ans = node_to_layers[node_ids['x']]\n",
    "    pruned_edges_ids = [(i, j) for i in range(m.shape[0]) for j in range(m.shape[0]) \\\n",
    "                    if m[i, j] != 0 and abs(ans[i] - ans[j]) > 1]\n",
    "    pruned_edges = [(id_to_node[i], id_to_node[j]) for i, j in pruned_edges_ids]\n",
    "    pruned_value = sum([m[i, j] for i, j in pruned_edges_ids])\n",
    "    \n",
    "    reach_ids = [set() for _ in range(len(node_ids))]\n",
    "    for i in range(len(node_ids) - 1, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        reach_ids[v].add(v)\n",
    "        for k in range(i + 1, m.shape[0]):\n",
    "            v_c = top_sort[k]\n",
    "            if m[v, v_c] != 0 and (v, v_c) not in pruned_edges_ids:\n",
    "                reach_ids[v] |= reach_ids[v_c]\n",
    "    conn_g = top_sort[-1] in reach_ids[top_sort[0]]\n",
    "                \n",
    "    return {'node_to_layer': {id_to_node[i]: ans.max() - l for i, l in enumerate(ans)},\n",
    "            'pruned_value': pruned_value, 'pruned_edges': pruned_edges,\n",
    "            'connected_graph': conn_g}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94affd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32632d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f0a1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.896551724137931, 0.896551724137931, 0.896551724137931, 0.896551724137931, 0.5862068965517241, 0.5862068965517241, 0.1280788177339901, 0.1280788177339901, 0.1280788177339901, 0.1428571428571428, 0.6896551724137931, 0.8866995073891626, 0.2068965517241379, 0.2068965517241379, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.7487684729064039, 0.8374384236453202, 0.5073891625615763, 0.5073891625615763, 0.3300492610837438, 0.3300492610837438, 0.3300492610837438, 0.3497536945812808, 0.3497536945812808, 0.3497536945812808, 0.18719211822660098, 0.8866995073891626, 0.044334975369458074, 0.044334975369458074, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.8620689655172413, 0.8866995073891626, 0.3694581280788177, 0.3694581280788177, 0.3448275862068966, 0.3448275862068966, 0.3448275862068966, 0.15270935960591125, 0.15270935960591125, 0.3793103448275862, 0.054187192118226535, 0.8620689655172413, 0.19704433497536944, 0.19704433497536944, 0.270935960591133, 0.270935960591133, 0.270935960591133, 0.039408866995073843, 0.01477832512315258, 0.7832512315270936, 0.024630541871921152, 0.024630541871921152, 0.009852216748768461, 0.009852216748768461, 0.009852216748768461, 0.044334975369458074, 0.044334975369458074, 0.01477832512315258, 0.03448275862068961, 0.8768472906403941, 0.049261083743842304, 0.049261083743842304, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.0, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508a197f88ed406e8d00b6b75f8e5fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_to_layer': {'x': 0, 'model_conv1': 0, 'model_bn1': 1, 'model_relu': 1, 'model_maxpool': 2, 'model_layer1_0_conv1': 2, 'model_layer1_0_bn1': 3, 'model_layer1_0_relu': 3, 'model_layer1_0_conv2': 4, 'model_layer1_0_bn2': 4, 'add': 5, 'model_layer1_0_relu_1': 5, 'model_layer1_1_conv1': 6, 'model_layer1_1_bn1': 6, 'model_layer1_1_relu': 7, 'model_layer1_1_conv2': 7, 'model_layer1_1_bn2': 8, 'add_1': 8, 'model_layer1_1_relu_1': 9, 'model_layer2_0_conv1': 10, 'model_layer2_0_bn1': 11, 'model_layer2_0_relu': 11, 'model_layer2_0_conv2': 12, 'model_layer2_0_bn2': 12, 'model_layer2_0_downsample_0': 9, 'model_layer2_0_downsample_1': 10, 'add_2': 13, 'model_layer2_0_relu_1': 13, 'model_layer2_1_conv1': 14, 'model_layer2_1_bn1': 14, 'model_layer2_1_relu': 15, 'model_layer2_1_conv2': 15, 'model_layer2_1_bn2': 16, 'add_3': 16, 'model_layer2_1_relu_1': 17, 'model_layer3_0_conv1': 18, 'model_layer3_0_bn1': 19, 'model_layer3_0_relu': 19, 'model_layer3_0_conv2': 20, 'model_layer3_0_bn2': 20, 'model_layer3_0_downsample_0': 17, 'model_layer3_0_downsample_1': 18, 'add_4': 21, 'model_layer3_0_relu_1': 21, 'model_layer3_1_conv1': 22, 'model_layer3_1_bn1': 22, 'model_layer3_1_relu': 23, 'model_layer3_1_conv2': 23, 'model_layer3_1_bn2': 24, 'add_5': 24, 'model_layer3_1_relu_1': 25, 'model_layer4_0_conv1': 26, 'model_layer4_0_bn1': 27, 'model_layer4_0_relu': 27, 'model_layer4_0_conv2': 28, 'model_layer4_0_bn2': 28, 'model_layer4_0_downsample_0': 25, 'model_layer4_0_downsample_1': 26, 'add_6': 29, 'model_layer4_0_relu_1': 29, 'model_layer4_1_conv1': 30, 'model_layer4_1_bn1': 30, 'model_layer4_1_relu': 31, 'model_layer4_1_conv2': 31, 'model_layer4_1_bn2': 32, 'add_7': 32, 'model_layer4_1_relu_1': 33, 'model_avgpool': 33, 'flatten': 34, 'model_fc': 34, 'output': 35}, 'pruned_value': 0, 'pruned_edges': [], 'connected_graph': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f22439931b42fbaa6b50126b740f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfa1d48116e459588caabaabc59aaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6e446d3abb42d482bc5ff9b987d7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.896551724137931, 0.896551724137931, 0.896551724137931, 0.896551724137931, 0.5862068965517241, 0.5862068965517241, 0.1280788177339901, 0.1280788177339901, 0.1280788177339901, 0.1428571428571428, 0.6896551724137931, 0.8866995073891626, 0.2068965517241379, 0.2068965517241379, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.7487684729064039, 0.8374384236453202, 0.5073891625615763, 0.5073891625615763, 0.3300492610837438, 0.3300492610837438, 0.3300492610837438, 0.3497536945812808, 0.3497536945812808, 0.3497536945812808, 0.18719211822660098, 0.8866995073891626, 0.044334975369458074, 0.044334975369458074, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.8620689655172413, 0.8866995073891626, 0.3694581280788177, 0.3694581280788177, 0.3448275862068966, 0.3448275862068966, 0.3448275862068966, 0.15270935960591125, 0.15270935960591125, 0.3793103448275862, 0.054187192118226535, 0.8620689655172413, 0.19704433497536944, 0.19704433497536944, 0.270935960591133, 0.270935960591133, 0.270935960591133, 0.039408866995073843, 0.01477832512315258, 0.7832512315270936, 0.024630541871921152, 0.024630541871921152, 0.009852216748768461, 0.009852216748768461, 0.009852216748768461, 0.044334975369458074, 0.044334975369458074, 0.01477832512315258, 0.03448275862068961, 0.8768472906403941, 0.049261083743842304, 0.049261083743842304, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.0, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05fb9ebb50343cfad778570b901a236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_to_layer': {'x': 0, 'model_conv1': 0, 'model_bn1': 0, 'model_relu': 1, 'model_maxpool': 1, 'model_layer1_0_conv1': 1, 'model_layer1_0_bn1': 2, 'model_layer1_0_relu': 2, 'model_layer1_0_conv2': 2, 'model_layer1_0_bn2': 3, 'add': 3, 'model_layer1_0_relu_1': 3, 'model_layer1_1_conv1': 4, 'model_layer1_1_bn1': 4, 'model_layer1_1_relu': 4, 'model_layer1_1_conv2': 5, 'model_layer1_1_bn2': 5, 'add_1': 5, 'model_layer1_1_relu_1': 6, 'model_layer2_0_conv1': 7, 'model_layer2_0_bn1': 7, 'model_layer2_0_relu': 7, 'model_layer2_0_conv2': 8, 'model_layer2_0_bn2': 8, 'model_layer2_0_downsample_0': 6, 'model_layer2_0_downsample_1': 6, 'add_2': 8, 'model_layer2_0_relu_1': 9, 'model_layer2_1_conv1': 9, 'model_layer2_1_bn1': 9, 'model_layer2_1_relu': 10, 'model_layer2_1_conv2': 10, 'model_layer2_1_bn2': 10, 'add_3': 11, 'model_layer2_1_relu_1': 11, 'model_layer3_0_conv1': 12, 'model_layer3_0_bn1': 12, 'model_layer3_0_relu': 13, 'model_layer3_0_conv2': 13, 'model_layer3_0_bn2': 13, 'model_layer3_0_downsample_0': 11, 'model_layer3_0_downsample_1': 12, 'add_4': 14, 'model_layer3_0_relu_1': 14, 'model_layer3_1_conv1': 14, 'model_layer3_1_bn1': 15, 'model_layer3_1_relu': 15, 'model_layer3_1_conv2': 15, 'model_layer3_1_bn2': 16, 'add_5': 16, 'model_layer3_1_relu_1': 16, 'model_layer4_0_conv1': 17, 'model_layer4_0_bn1': 18, 'model_layer4_0_relu': 18, 'model_layer4_0_conv2': 18, 'model_layer4_0_bn2': 19, 'model_layer4_0_downsample_0': 17, 'model_layer4_0_downsample_1': 17, 'add_6': 19, 'model_layer4_0_relu_1': 19, 'model_layer4_1_conv1': 20, 'model_layer4_1_bn1': 20, 'model_layer4_1_relu': 20, 'model_layer4_1_conv2': 21, 'model_layer4_1_bn2': 21, 'add_7': 21, 'model_layer4_1_relu_1': 22, 'model_avgpool': 22, 'flatten': 22, 'model_fc': 23, 'output': 23}, 'pruned_value': 0, 'pruned_edges': [], 'connected_graph': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d2b3dbaed4e08bae4badb92059ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f93cdc0944f4ccc9ddc8006f50de2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6e4519a6704ccba4ba2c2ff3930aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.896551724137931, 0.896551724137931, 0.896551724137931, 0.896551724137931, 0.5862068965517241, 0.5862068965517241, 0.1280788177339901, 0.1280788177339901, 0.1280788177339901, 0.1428571428571428, 0.6896551724137931, 0.8866995073891626, 0.2068965517241379, 0.2068965517241379, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.7487684729064039, 0.8374384236453202, 0.5073891625615763, 0.5073891625615763, 0.3300492610837438, 0.3300492610837438, 0.3300492610837438, 0.3497536945812808, 0.3497536945812808, 0.3497536945812808, 0.18719211822660098, 0.8866995073891626, 0.044334975369458074, 0.044334975369458074, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.8620689655172413, 0.8866995073891626, 0.3694581280788177, 0.3694581280788177, 0.3448275862068966, 0.3448275862068966, 0.3448275862068966, 0.15270935960591125, 0.15270935960591125, 0.3793103448275862, 0.054187192118226535, 0.8620689655172413, 0.19704433497536944, 0.19704433497536944, 0.270935960591133, 0.270935960591133, 0.270935960591133, 0.039408866995073843, 0.01477832512315258, 0.7832512315270936, 0.024630541871921152, 0.024630541871921152, 0.009852216748768461, 0.009852216748768461, 0.009852216748768461, 0.044334975369458074, 0.044334975369458074, 0.01477832512315258, 0.03448275862068961, 0.8768472906403941, 0.049261083743842304, 0.049261083743842304, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.0, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad304c9a8d9447ae90521389338a2b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_to_layer': {'x': 0, 'model_conv1': 0, 'model_bn1': 0, 'model_relu': 0, 'model_maxpool': 1, 'model_layer1_0_conv1': 1, 'model_layer1_0_bn1': 1, 'model_layer1_0_relu': 1, 'model_layer1_0_conv2': 2, 'model_layer1_0_bn2': 2, 'add': 2, 'model_layer1_0_relu_1': 2, 'model_layer1_1_conv1': 3, 'model_layer1_1_bn1': 3, 'model_layer1_1_relu': 3, 'model_layer1_1_conv2': 3, 'model_layer1_1_bn2': 4, 'add_1': 4, 'model_layer1_1_relu_1': 4, 'model_layer2_0_conv1': 5, 'model_layer2_0_bn1': 5, 'model_layer2_0_relu': 5, 'model_layer2_0_conv2': 6, 'model_layer2_0_bn2': 6, 'model_layer2_0_downsample_0': 4, 'model_layer2_0_downsample_1': 5, 'add_2': 6, 'model_layer2_0_relu_1': 6, 'model_layer2_1_conv1': 7, 'model_layer2_1_bn1': 7, 'model_layer2_1_relu': 7, 'model_layer2_1_conv2': 7, 'model_layer2_1_bn2': 8, 'add_3': 8, 'model_layer2_1_relu_1': 8, 'model_layer3_0_conv1': 9, 'model_layer3_0_bn1': 9, 'model_layer3_0_relu': 9, 'model_layer3_0_conv2': 10, 'model_layer3_0_bn2': 10, 'model_layer3_0_downsample_0': 8, 'model_layer3_0_downsample_1': 9, 'add_4': 10, 'model_layer3_0_relu_1': 10, 'model_layer3_1_conv1': 11, 'model_layer3_1_bn1': 11, 'model_layer3_1_relu': 11, 'model_layer3_1_conv2': 11, 'model_layer3_1_bn2': 12, 'add_5': 12, 'model_layer3_1_relu_1': 12, 'model_layer4_0_conv1': 13, 'model_layer4_0_bn1': 13, 'model_layer4_0_relu': 13, 'model_layer4_0_conv2': 14, 'model_layer4_0_bn2': 14, 'model_layer4_0_downsample_0': 12, 'model_layer4_0_downsample_1': 13, 'add_6': 14, 'model_layer4_0_relu_1': 14, 'model_layer4_1_conv1': 15, 'model_layer4_1_bn1': 15, 'model_layer4_1_relu': 15, 'model_layer4_1_conv2': 15, 'model_layer4_1_bn2': 16, 'add_7': 16, 'model_layer4_1_relu_1': 16, 'model_avgpool': 16, 'flatten': 17, 'model_fc': 17, 'output': 17}, 'pruned_value': 0, 'pruned_edges': [], 'connected_graph': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1676bb73d77415bb36242648f738536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53372a9b16dd493da2b6bf7977a90510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee0296887fd4d25a25f984a313df350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.896551724137931, 0.896551724137931, 0.896551724137931, 0.896551724137931, 0.5862068965517241, 0.5862068965517241, 0.1280788177339901, 0.1280788177339901, 0.1280788177339901, 0.1428571428571428, 0.6896551724137931, 0.8866995073891626, 0.2068965517241379, 0.2068965517241379, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.7487684729064039, 0.8374384236453202, 0.5073891625615763, 0.5073891625615763, 0.3300492610837438, 0.3300492610837438, 0.3300492610837438, 0.3497536945812808, 0.3497536945812808, 0.3497536945812808, 0.18719211822660098, 0.8866995073891626, 0.044334975369458074, 0.044334975369458074, 0.029556650246305383, 0.029556650246305383, 0.029556650246305383, 0.024630541871921152, 0.8620689655172413, 0.8866995073891626, 0.3694581280788177, 0.3694581280788177, 0.3448275862068966, 0.3448275862068966, 0.3448275862068966, 0.15270935960591125, 0.15270935960591125, 0.3793103448275862, 0.054187192118226535, 0.8620689655172413, 0.19704433497536944, 0.19704433497536944, 0.270935960591133, 0.270935960591133, 0.270935960591133, 0.039408866995073843, 0.01477832512315258, 0.7832512315270936, 0.024630541871921152, 0.024630541871921152, 0.009852216748768461, 0.009852216748768461, 0.009852216748768461, 0.044334975369458074, 0.044334975369458074, 0.01477832512315258, 0.03448275862068961, 0.8768472906403941, 0.049261083743842304, 0.049261083743842304, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.024630541871921152, 0.0, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.8768472906403941, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb234dd0b7a499a94f54fd5c1411d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_to_layer': {'x': 0, 'model_conv1': 0, 'model_bn1': 0, 'model_relu': 0, 'model_maxpool': 0, 'model_layer1_0_conv1': 1, 'model_layer1_0_bn1': 1, 'model_layer1_0_relu': 1, 'model_layer1_0_conv2': 1, 'model_layer1_0_bn2': 1, 'add': 2, 'model_layer1_0_relu_1': 2, 'model_layer1_1_conv1': 2, 'model_layer1_1_bn1': 2, 'model_layer1_1_relu': 2, 'model_layer1_1_conv2': 3, 'model_layer1_1_bn2': 3, 'add_1': 3, 'model_layer1_1_relu_1': 3, 'model_layer2_0_conv1': 4, 'model_layer2_0_bn1': 4, 'model_layer2_0_relu': 4, 'model_layer2_0_conv2': 4, 'model_layer2_0_bn2': 5, 'model_layer2_0_downsample_0': 3, 'model_layer2_0_downsample_1': 4, 'add_2': 5, 'model_layer2_0_relu_1': 5, 'model_layer2_1_conv1': 5, 'model_layer2_1_bn1': 5, 'model_layer2_1_relu': 6, 'model_layer2_1_conv2': 6, 'model_layer2_1_bn2': 6, 'add_3': 6, 'model_layer2_1_relu_1': 6, 'model_layer3_0_conv1': 7, 'model_layer3_0_bn1': 7, 'model_layer3_0_relu': 7, 'model_layer3_0_conv2': 8, 'model_layer3_0_bn2': 8, 'model_layer3_0_downsample_0': 7, 'model_layer3_0_downsample_1': 7, 'add_4': 8, 'model_layer3_0_relu_1': 8, 'model_layer3_1_conv1': 8, 'model_layer3_1_bn1': 9, 'model_layer3_1_relu': 9, 'model_layer3_1_conv2': 9, 'model_layer3_1_bn2': 9, 'add_5': 9, 'model_layer3_1_relu_1': 10, 'model_layer4_0_conv1': 10, 'model_layer4_0_bn1': 10, 'model_layer4_0_relu': 11, 'model_layer4_0_conv2': 11, 'model_layer4_0_bn2': 11, 'model_layer4_0_downsample_0': 10, 'model_layer4_0_downsample_1': 10, 'add_6': 11, 'model_layer4_0_relu_1': 11, 'model_layer4_1_conv1': 12, 'model_layer4_1_bn1': 12, 'model_layer4_1_relu': 12, 'model_layer4_1_conv2': 12, 'model_layer4_1_bn2': 12, 'add_7': 13, 'model_layer4_1_relu_1': 13, 'model_avgpool': 13, 'flatten': 13, 'model_fc': 13, 'output': 14}, 'pruned_value': 0, 'pruned_edges': [], 'connected_graph': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2d20ca5add48c0ac34d30ceac374d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb21fde9266c454d87d80dfe5b7099b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e7a8c3383e420f9650619018b5d2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### find the best solution\n",
    "# import pickle\n",
    "# with open('./naive_mean.pckl', 'rb') as inp:\n",
    "#     eval_dict, fine_dict = pickle.loads(inp.read())\n",
    "eval_dict = {}\n",
    "fine_dict = {}\n",
    "\n",
    "for edge_mem in range(2,6):\n",
    "    if edge_mem in eval_dict and edge_mem in fine_dict:\n",
    "        print ('skip', edge_mem)\n",
    "        continue\n",
    "    #if edge_mem == 3 and attemp > 0:\n",
    "    #    continue\n",
    "    #if edge_mem == 4 and attemp > 0:\n",
    "    #    continue\n",
    "\n",
    "    model = ResNet18(8)\n",
    "    model.load_state_dict(torch.load('../data/model_last.ckpt', map_location='cpu'))\n",
    "    warp = GraphInterperterWithGamma(model)\n",
    "\n",
    "    named_dict = dict(model.named_modules())\n",
    "\n",
    "    for node in warp.graph.nodes:\n",
    "        if node.op == 'call_module':\n",
    "            pass\n",
    "            # print('Norm', np.sqrt(sum([(p ** 2).sum().item() \\\n",
    "            #                            for p in named_dict[node.target].parameters()])))\n",
    "        # print(node.op, node.name, node.args)\n",
    "        # break\n",
    "\n",
    "\n",
    "    edges, weights, a, b = module_to_graph(ResNet18())\n",
    "    # edges, weights\n",
    "    edges[:10], list(weights.items())[:10]\n",
    "    # edges_importance = [1]*len(edges)  ### WHY???\n",
    "    print(edges_importance)\n",
    "\n",
    "    best_pruned = 1e10\n",
    "    best_val = None\n",
    "    for s in tqdm(all_sorts):\n",
    "        # for mem=8 the computation takes time\n",
    "        res = dp_for_top_sort(edges, {k: 1 for k in weights}, edges_importance, s, edge_mem)  \n",
    "        if res['connected_graph'] == True and best_pruned > res['pruned_value'] or best_val is None:\n",
    "            best_pruned = res['pruned_value']\n",
    "            best_val = res\n",
    "\n",
    "        if best_pruned == 0:\n",
    "            print(res)\n",
    "            break\n",
    "\n",
    "\n",
    "    model = ResNet18(8)\n",
    "    model.load_state_dict(torch.load('../data/model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "    wrapped = torch.fx.symbolic_trace(model)\n",
    "    pruned = PrunedModel(wrapped, {k:1.0 if k not in best_val['pruned_edges'] else 0.0 for k in edges }, inter)\n",
    "\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "    if edge_mem not in eval_dict:\n",
    "        eval_dict[edge_mem] = []\n",
    "    eval_dict[edge_mem].append(res)\n",
    "\n",
    "    train_loop(pruned, train_dl, test_dl, 9999999999, 1, 1e-3,  \"cpu\")\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "    if edge_mem not in fine_dict:\n",
    "        fine_dict[edge_mem] = []\n",
    "    fine_dict[edge_mem].append(res)\n",
    "\n",
    "    import pickle\n",
    "    with open('naive_mean.pckl', 'wb') as out:\n",
    "        out.write(pickle.dumps([eval_dict, fine_dict]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73532c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [0.7201250195503235],\n",
       " 3: [0.7294999957084656],\n",
       " 4: [0.7146250009536743],\n",
       " 5: [0.7152500152587891]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "032e7555-ce76-4008-b956-afac6cd5b1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [0.7331249713897705],\n",
       " 3: [0.7331249713897705],\n",
       " 4: [0.7331249713897705],\n",
       " 5: [0.7331249713897705]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e981612-3d19-4e1b-886d-4e1448d36320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0c5a7caa314ac3a687c9a8eed76ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7152500152587891"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loop(model, test_dl, nc=8, return_ll=False, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d0a2c-ef6f-4c52-87c9-f4f9460e2209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda48dd8-cb35-4446-ae3b-532a49b2bfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b9a69a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ac5888c94b4757ae0a6adc6649c3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731f6bd97e7547d69c9bc9ad188f6834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if edge_mem not in eval_dict:\n",
    "    eval_dict[edge_mem] = []\n",
    "eval_dict[edge_mem].append(res)\n",
    "\n",
    "train_loop(pruned, train_dl, test_dl, 9999999999, 1, 1e-3,  \"cpu\")\n",
    "res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "if edge_mem not in fine_dict:\n",
    "    fine_dict[edge_mem] = []\n",
    "fine_dict[edge_mem].append(res)\n",
    "\n",
    "import pickle\n",
    "with open('naive.pckl', 'wb') as out:\n",
    "    out.write(pickle.dumps([eval_dict, fine_dict]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee91dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125], 3: [0.125], 4: [0.12524999678134918], 5: [0.23675000667572021]},\n",
       " {2: [0.5216249823570251],\n",
       "  3: [0.5532500147819519],\n",
       "  4: [0.656624972820282],\n",
       "  5: [0.6958749890327454]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('naive.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11b325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125, 0.12600000202655792, 0.125],\n",
       "  3: [0.125, 0.125, 0.125],\n",
       "  4: [0.12524999678134918, 0.12524999678134918, 0.125],\n",
       "  5: [0.1368750035762787, 0.125, 0.21812500059604645]},\n",
       " {2: [0.5640000104904175, 0.5180000066757202, 0.5730000138282776],\n",
       "  3: [0.5625, 0.5435000061988831, 0.5742499828338623],\n",
       "  4: [0.6353750228881836, 0.6573749780654907, 0.6784999966621399],\n",
       "  5: [0.6420000195503235, 0.6677500009536743, 0.6775000095367432]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('randn.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361d4743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125], 3: [0.125], 4: [0.1264999955892563], 5: [0.2516250014305115]},\n",
       " {2: [0.5951250195503235],\n",
       "  3: [0.6156250238418579],\n",
       "  4: [0.6588749885559082],\n",
       "  5: [0.6837499737739563]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('naive_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ea4825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.12962499260902405, 0.125, 0.125],\n",
       "  3: [0.125, 0.125, 0.125],\n",
       "  4: [0.12612499296665192, 0.12612499296665192, 0.125],\n",
       "  5: [0.12587499618530273, 0.12587499618530273]},\n",
       " {2: [0.5892500281333923, 0.5241249799728394, 0.6132500171661377],\n",
       "  3: [0.5706250071525574, 0.6041250228881836, 0.5644999742507935],\n",
       "  4: [0.6047499775886536, 0.6507499814033508, 0.6359999775886536],\n",
       "  5: [0.6508749723434448, 0.6942499876022339]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('random_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
