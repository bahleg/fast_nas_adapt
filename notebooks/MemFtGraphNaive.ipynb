{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9879be41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.module2graph import GraphInterperterWithGamma\n",
    "from src.resnet18 import ResNet18\n",
    "import numpy as np\n",
    "\n",
    "import graphviz\n",
    "import itertools\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Tuple, Dict # actually we don't need it for py>=3.9, but I have 3.8 on my laptop\n",
    "from src.utils import train_loop, test_loop\n",
    "#from numba import njit\n",
    "from src.cifar_data import get_dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc3e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward for target model with gamma values for each edge.\n",
    "# means - mean values for arguments\n",
    "def forward_with_gammas(model, gammas: Dict[Tuple[str, str], torch.Tensor], \n",
    "                        means: Dict[str, torch.Tensor] = None, *torch_model_args):\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "            gammas_node = [int(gammas[e])  if (e is not None) else 1 for e in edges ]\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g  for a0,a,g in zip(node.args,\n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            #print (len(args), len(node.args))\n",
    "            #print (node, [a for a in node.args])\n",
    "            #print (node, [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            args =  [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args[1:], \n",
    "                                                                        args, gammas_node)]\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args, \n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            \n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "            \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return result, env # currently ignorign means for output\n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return result\n",
    "\n",
    "# a wrapper that takes model and uses forward_with_Gammas\n",
    "class PrunedModel(torch.nn.Module):\n",
    "    def __init__(self, base, prune_dict, means = None):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.prune_dict = prune_dict\n",
    "        self.means = means \n",
    "    def forward(self, x):\n",
    "        return forward_with_gammas(self.base, self.prune_dict,  self.means, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22897ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets intermediate representations of nodes\n",
    "def get_inter(model, *torch_model_args) -> dict:\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    inter = {}\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            \n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            #print (len(args), len(node.args))\n",
    "            #print ([a.shape for a in load_arg(node.args)], [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            \n",
    "            for a_, a in zip(node.args[1:], args):\n",
    "                inter[a_] = a\n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "    \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return inter \n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651c865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dl, test_dl = get_dataloaders([0,1,2,3,4,5,6,7], )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb347af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('x', 'model_conv1'),\n",
       "  ('model_conv1', 'model_bn1'),\n",
       "  ('model_bn1', 'model_relu'),\n",
       "  ('model_relu', 'model_maxpool'),\n",
       "  ('model_maxpool', 'model_layer1_0_conv1'),\n",
       "  ('model_layer1_0_conv1', 'model_layer1_0_bn1'),\n",
       "  ('model_layer1_0_bn1', 'model_layer1_0_relu'),\n",
       "  ('model_layer1_0_relu', 'model_layer1_0_conv2'),\n",
       "  ('model_layer1_0_conv2', 'model_layer1_0_bn2'),\n",
       "  ('model_layer1_0_bn2', 'add'),\n",
       "  ('model_maxpool', 'add'),\n",
       "  ('add', 'model_layer1_0_relu_1'),\n",
       "  ('model_layer1_0_relu_1', 'model_layer1_1_conv1'),\n",
       "  ('model_layer1_1_conv1', 'model_layer1_1_bn1'),\n",
       "  ('model_layer1_1_bn1', 'model_layer1_1_relu'),\n",
       "  ('model_layer1_1_relu', 'model_layer1_1_conv2'),\n",
       "  ('model_layer1_1_conv2', 'model_layer1_1_bn2'),\n",
       "  ('model_layer1_1_bn2', 'add_1'),\n",
       "  ('model_layer1_0_relu_1', 'add_1'),\n",
       "  ('add_1', 'model_layer1_1_relu_1'),\n",
       "  ('model_layer1_1_relu_1', 'model_layer2_0_conv1'),\n",
       "  ('model_layer2_0_conv1', 'model_layer2_0_bn1'),\n",
       "  ('model_layer2_0_bn1', 'model_layer2_0_relu'),\n",
       "  ('model_layer2_0_relu', 'model_layer2_0_conv2'),\n",
       "  ('model_layer2_0_conv2', 'model_layer2_0_bn2'),\n",
       "  ('model_layer1_1_relu_1', 'model_layer2_0_downsample_0'),\n",
       "  ('model_layer2_0_downsample_0', 'model_layer2_0_downsample_1'),\n",
       "  ('model_layer2_0_bn2', 'add_2'),\n",
       "  ('model_layer2_0_downsample_1', 'add_2'),\n",
       "  ('add_2', 'model_layer2_0_relu_1'),\n",
       "  ('model_layer2_0_relu_1', 'model_layer2_1_conv1'),\n",
       "  ('model_layer2_1_conv1', 'model_layer2_1_bn1'),\n",
       "  ('model_layer2_1_bn1', 'model_layer2_1_relu'),\n",
       "  ('model_layer2_1_relu', 'model_layer2_1_conv2'),\n",
       "  ('model_layer2_1_conv2', 'model_layer2_1_bn2'),\n",
       "  ('model_layer2_1_bn2', 'add_3'),\n",
       "  ('model_layer2_0_relu_1', 'add_3'),\n",
       "  ('add_3', 'model_layer2_1_relu_1'),\n",
       "  ('model_layer2_1_relu_1', 'model_layer3_0_conv1'),\n",
       "  ('model_layer3_0_conv1', 'model_layer3_0_bn1'),\n",
       "  ('model_layer3_0_bn1', 'model_layer3_0_relu'),\n",
       "  ('model_layer3_0_relu', 'model_layer3_0_conv2'),\n",
       "  ('model_layer3_0_conv2', 'model_layer3_0_bn2'),\n",
       "  ('model_layer2_1_relu_1', 'model_layer3_0_downsample_0'),\n",
       "  ('model_layer3_0_downsample_0', 'model_layer3_0_downsample_1'),\n",
       "  ('model_layer3_0_bn2', 'add_4'),\n",
       "  ('model_layer3_0_downsample_1', 'add_4'),\n",
       "  ('add_4', 'model_layer3_0_relu_1'),\n",
       "  ('model_layer3_0_relu_1', 'model_layer3_1_conv1'),\n",
       "  ('model_layer3_1_conv1', 'model_layer3_1_bn1'),\n",
       "  ('model_layer3_1_bn1', 'model_layer3_1_relu'),\n",
       "  ('model_layer3_1_relu', 'model_layer3_1_conv2'),\n",
       "  ('model_layer3_1_conv2', 'model_layer3_1_bn2'),\n",
       "  ('model_layer3_1_bn2', 'add_5'),\n",
       "  ('model_layer3_0_relu_1', 'add_5'),\n",
       "  ('add_5', 'model_layer3_1_relu_1'),\n",
       "  ('model_layer3_1_relu_1', 'model_layer4_0_conv1'),\n",
       "  ('model_layer4_0_conv1', 'model_layer4_0_bn1'),\n",
       "  ('model_layer4_0_bn1', 'model_layer4_0_relu'),\n",
       "  ('model_layer4_0_relu', 'model_layer4_0_conv2'),\n",
       "  ('model_layer4_0_conv2', 'model_layer4_0_bn2'),\n",
       "  ('model_layer3_1_relu_1', 'model_layer4_0_downsample_0'),\n",
       "  ('model_layer4_0_downsample_0', 'model_layer4_0_downsample_1'),\n",
       "  ('model_layer4_0_bn2', 'add_6'),\n",
       "  ('model_layer4_0_downsample_1', 'add_6'),\n",
       "  ('add_6', 'model_layer4_0_relu_1'),\n",
       "  ('model_layer4_0_relu_1', 'model_layer4_1_conv1'),\n",
       "  ('model_layer4_1_conv1', 'model_layer4_1_bn1'),\n",
       "  ('model_layer4_1_bn1', 'model_layer4_1_relu'),\n",
       "  ('model_layer4_1_relu', 'model_layer4_1_conv2'),\n",
       "  ('model_layer4_1_conv2', 'model_layer4_1_bn2'),\n",
       "  ('model_layer4_1_bn2', 'add_7'),\n",
       "  ('model_layer4_0_relu_1', 'add_7'),\n",
       "  ('add_7', 'model_layer4_1_relu_1'),\n",
       "  ('model_layer4_1_relu_1', 'model_avgpool'),\n",
       "  ('model_avgpool', 'flatten'),\n",
       "  ('flatten', 'model_fc'),\n",
       "  ('model_fc', 'output')],\n",
       " {'x': 0,\n",
       "  'model_conv1': 9408,\n",
       "  'model_bn1': 128,\n",
       "  'model_relu': 0,\n",
       "  'model_maxpool': 0,\n",
       "  'model_layer1_0_conv1': 36864,\n",
       "  'model_layer1_0_bn1': 128,\n",
       "  'model_layer1_0_relu': 0,\n",
       "  'model_layer1_0_conv2': 36864,\n",
       "  'model_layer1_0_bn2': 128,\n",
       "  'add': 0,\n",
       "  'model_layer1_0_relu_1': 0,\n",
       "  'model_layer1_1_conv1': 36864,\n",
       "  'model_layer1_1_bn1': 128,\n",
       "  'model_layer1_1_relu': 0,\n",
       "  'model_layer1_1_conv2': 36864,\n",
       "  'model_layer1_1_bn2': 128,\n",
       "  'add_1': 0,\n",
       "  'model_layer1_1_relu_1': 0,\n",
       "  'model_layer2_0_conv1': 73728,\n",
       "  'model_layer2_0_bn1': 256,\n",
       "  'model_layer2_0_relu': 0,\n",
       "  'model_layer2_0_conv2': 147456,\n",
       "  'model_layer2_0_bn2': 256,\n",
       "  'model_layer2_0_downsample_0': 8192,\n",
       "  'model_layer2_0_downsample_1': 256,\n",
       "  'add_2': 0,\n",
       "  'model_layer2_0_relu_1': 0,\n",
       "  'model_layer2_1_conv1': 147456,\n",
       "  'model_layer2_1_bn1': 256,\n",
       "  'model_layer2_1_relu': 0,\n",
       "  'model_layer2_1_conv2': 147456,\n",
       "  'model_layer2_1_bn2': 256,\n",
       "  'add_3': 0,\n",
       "  'model_layer2_1_relu_1': 0,\n",
       "  'model_layer3_0_conv1': 294912,\n",
       "  'model_layer3_0_bn1': 512,\n",
       "  'model_layer3_0_relu': 0,\n",
       "  'model_layer3_0_conv2': 589824,\n",
       "  'model_layer3_0_bn2': 512,\n",
       "  'model_layer3_0_downsample_0': 32768,\n",
       "  'model_layer3_0_downsample_1': 512,\n",
       "  'add_4': 0,\n",
       "  'model_layer3_0_relu_1': 0,\n",
       "  'model_layer3_1_conv1': 589824,\n",
       "  'model_layer3_1_bn1': 512,\n",
       "  'model_layer3_1_relu': 0,\n",
       "  'model_layer3_1_conv2': 589824,\n",
       "  'model_layer3_1_bn2': 512,\n",
       "  'add_5': 0,\n",
       "  'model_layer3_1_relu_1': 0,\n",
       "  'model_layer4_0_conv1': 1179648,\n",
       "  'model_layer4_0_bn1': 1024,\n",
       "  'model_layer4_0_relu': 0,\n",
       "  'model_layer4_0_conv2': 2359296,\n",
       "  'model_layer4_0_bn2': 1024,\n",
       "  'model_layer4_0_downsample_0': 131072,\n",
       "  'model_layer4_0_downsample_1': 1024,\n",
       "  'add_6': 0,\n",
       "  'model_layer4_0_relu_1': 0,\n",
       "  'model_layer4_1_conv1': 2359296,\n",
       "  'model_layer4_1_bn1': 1024,\n",
       "  'model_layer4_1_relu': 0,\n",
       "  'model_layer4_1_conv2': 2359296,\n",
       "  'model_layer4_1_bn2': 1024,\n",
       "  'add_7': 0,\n",
       "  'model_layer4_1_relu_1': 0,\n",
       "  'model_avgpool': 0,\n",
       "  'flatten': 0,\n",
       "  'model_fc': 5130,\n",
       "  'output': 0},\n",
       " {'x': 0,\n",
       "  'model_conv1': 0,\n",
       "  'model_bn1': 0,\n",
       "  'model_relu': 0,\n",
       "  'model_maxpool': 0,\n",
       "  'model_layer1_0_conv1': 0,\n",
       "  'model_layer1_0_bn1': 0,\n",
       "  'model_layer1_0_relu': 0,\n",
       "  'model_layer1_0_conv2': 0,\n",
       "  'model_layer1_0_bn2': 0,\n",
       "  'model_layer1_0_relu_1': 0,\n",
       "  'model_layer1_1_conv1': 0,\n",
       "  'model_layer1_1_bn1': 0,\n",
       "  'model_layer1_1_relu': 0,\n",
       "  'model_layer1_1_conv2': 0,\n",
       "  'model_layer1_1_bn2': 0,\n",
       "  'model_layer1_1_relu_1': 0,\n",
       "  'model_layer2_0_conv1': 0,\n",
       "  'model_layer2_0_bn1': 0,\n",
       "  'model_layer2_0_relu': 0,\n",
       "  'model_layer2_0_conv2': 0,\n",
       "  'model_layer2_0_bn2': 0,\n",
       "  'model_layer2_0_downsample_0': 0,\n",
       "  'model_layer2_0_downsample_1': 0,\n",
       "  'model_layer2_0_relu_1': 0,\n",
       "  'model_layer2_1_conv1': 0,\n",
       "  'model_layer2_1_bn1': 0,\n",
       "  'model_layer2_1_relu': 0,\n",
       "  'model_layer2_1_conv2': 0,\n",
       "  'model_layer2_1_bn2': 0,\n",
       "  'model_layer2_1_relu_1': 0,\n",
       "  'model_layer3_0_conv1': 0,\n",
       "  'model_layer3_0_bn1': 0,\n",
       "  'model_layer3_0_relu': 0,\n",
       "  'model_layer3_0_conv2': 0,\n",
       "  'model_layer3_0_bn2': 0,\n",
       "  'model_layer3_0_downsample_0': 0,\n",
       "  'model_layer3_0_downsample_1': 0,\n",
       "  'model_layer3_0_relu_1': 0,\n",
       "  'model_layer3_1_conv1': 0,\n",
       "  'model_layer3_1_bn1': 0,\n",
       "  'model_layer3_1_relu': 0,\n",
       "  'model_layer3_1_conv2': 0,\n",
       "  'model_layer3_1_bn2': 0,\n",
       "  'model_layer3_1_relu_1': 0,\n",
       "  'model_layer4_0_conv1': 0,\n",
       "  'model_layer4_0_bn1': 0,\n",
       "  'model_layer4_0_relu': 0,\n",
       "  'model_layer4_0_conv2': 0,\n",
       "  'model_layer4_0_bn2': 0,\n",
       "  'model_layer4_0_downsample_0': 0,\n",
       "  'model_layer4_0_downsample_1': 0,\n",
       "  'model_layer4_0_relu_1': 0,\n",
       "  'model_layer4_1_conv1': 0,\n",
       "  'model_layer4_1_bn1': 0,\n",
       "  'model_layer4_1_relu': 0,\n",
       "  'model_layer4_1_conv2': 0,\n",
       "  'model_layer4_1_bn2': 0,\n",
       "  'model_layer4_1_relu_1': 0,\n",
       "  'model_avgpool': 0,\n",
       "  'model_fc': 0},\n",
       " {'x': 0,\n",
       "  'model_conv1': 0,\n",
       "  'model_bn1': 0,\n",
       "  'model_relu': 0,\n",
       "  'model_maxpool': 0,\n",
       "  'model_layer1_0_conv1': 0,\n",
       "  'model_layer1_0_bn1': 0,\n",
       "  'model_layer1_0_relu': 0,\n",
       "  'model_layer1_0_conv2': 0,\n",
       "  'model_layer1_0_bn2': 0,\n",
       "  'model_layer1_0_relu_1': 0,\n",
       "  'model_layer1_1_conv1': 0,\n",
       "  'model_layer1_1_bn1': 0,\n",
       "  'model_layer1_1_relu': 0,\n",
       "  'model_layer1_1_conv2': 0,\n",
       "  'model_layer1_1_bn2': 0,\n",
       "  'model_layer1_1_relu_1': 0,\n",
       "  'model_layer2_0_conv1': 0,\n",
       "  'model_layer2_0_bn1': 0,\n",
       "  'model_layer2_0_relu': 0,\n",
       "  'model_layer2_0_conv2': 0,\n",
       "  'model_layer2_0_bn2': 0,\n",
       "  'model_layer2_0_downsample_0': 0,\n",
       "  'model_layer2_0_downsample_1': 0,\n",
       "  'model_layer2_0_relu_1': 0,\n",
       "  'model_layer2_1_conv1': 0,\n",
       "  'model_layer2_1_bn1': 0,\n",
       "  'model_layer2_1_relu': 0,\n",
       "  'model_layer2_1_conv2': 0,\n",
       "  'model_layer2_1_bn2': 0,\n",
       "  'model_layer2_1_relu_1': 0,\n",
       "  'model_layer3_0_conv1': 0,\n",
       "  'model_layer3_0_bn1': 0,\n",
       "  'model_layer3_0_relu': 0,\n",
       "  'model_layer3_0_conv2': 0,\n",
       "  'model_layer3_0_bn2': 0,\n",
       "  'model_layer3_0_downsample_0': 0,\n",
       "  'model_layer3_0_downsample_1': 0,\n",
       "  'model_layer3_0_relu_1': 0,\n",
       "  'model_layer3_1_conv1': 0,\n",
       "  'model_layer3_1_bn1': 0,\n",
       "  'model_layer3_1_relu': 0,\n",
       "  'model_layer3_1_conv2': 0,\n",
       "  'model_layer3_1_bn2': 0,\n",
       "  'model_layer3_1_relu_1': 0,\n",
       "  'model_layer4_0_conv1': 0,\n",
       "  'model_layer4_0_bn1': 0,\n",
       "  'model_layer4_0_relu': 0,\n",
       "  'model_layer4_0_conv2': 0,\n",
       "  'model_layer4_0_bn2': 0,\n",
       "  'model_layer4_0_downsample_0': 0,\n",
       "  'model_layer4_0_downsample_1': 0,\n",
       "  'model_layer4_0_relu_1': 0,\n",
       "  'model_layer4_1_conv1': 0,\n",
       "  'model_layer4_1_bn1': 0,\n",
       "  'model_layer4_1_relu': 0,\n",
       "  'model_layer4_1_conv2': 0,\n",
       "  'model_layer4_1_bn2': 0,\n",
       "  'model_layer4_1_relu_1': 0,\n",
       "  'model_avgpool': 0,\n",
       "  'model_fc': 0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean \n",
    "\n",
    "def module_to_graph(m: torch.nn.Module):\n",
    "    graph = torch.fx.symbolic_trace(m).graph\n",
    "    named_dict = dict(m.named_modules())\n",
    "    edges = [] # (from, to)\n",
    "    grad = {'x': 0}\n",
    "    params = {'x': 0}\n",
    "    weights = {'x': 0} # node: params\n",
    "    means = {}\n",
    "    for node in graph.nodes:\n",
    "    \n",
    "        # no placeholder and call_mathod\n",
    "        if node.op == 'call_module':\n",
    "            n_params = 0\n",
    "            grad_1 = []\n",
    "            params_1 = []\n",
    "            for p in named_dict[node.target].parameters():\n",
    "                n_params += p.numel()\n",
    "                grad_1.append(p.grad)\n",
    "                params_1.append(p)\n",
    "            try:\n",
    "                grad[node.name] = torch.mean(torch.stack(grad_1))\n",
    "                params[node.name] = torch.mean(torch.stack(params_1))\n",
    "            except:\n",
    "                grad[node.name] = 0\n",
    "                params[node.name] = 0\n",
    "            weights[node.name] = n_params\n",
    "            assert len(node.args) == 1\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "        elif node.op == 'call_function':\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "            weights[node.name] = 0\n",
    "        elif node.op == 'output':\n",
    "            try:\n",
    "                edges.append((node.args[0][0].name, node.name))\n",
    "            except:\n",
    "                edges.append((node.args[0].name, node.name))\n",
    "            weights['output'] = 0\n",
    "        \n",
    "        #if  len(edges)>0 and edges[-1] == ('model_maxpool', 'add'):\n",
    "        #    print (node.args, node.name, node.op)\n",
    "    return edges, {'_'.join(k.split('.')): v for k, v in weights.items()}, {'_'.join(k.split('.')): v for k, v in params.items()}, {'_'.join(k.split('.')): v for k, v in grad.items()}\n",
    "\n",
    "module_to_graph(ResNet18())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab87901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('x', 'model_conv1'),\n",
       "  ('model_conv1', 'model_bn1'),\n",
       "  ('model_bn1', 'model_relu'),\n",
       "  ('model_relu', 'model_maxpool'),\n",
       "  ('model_maxpool', 'model_layer1_0_conv1'),\n",
       "  ('model_layer1_0_conv1', 'model_layer1_0_bn1'),\n",
       "  ('model_layer1_0_bn1', 'model_layer1_0_relu'),\n",
       "  ('model_layer1_0_relu', 'model_layer1_0_conv2'),\n",
       "  ('model_layer1_0_conv2', 'model_layer1_0_bn2'),\n",
       "  ('model_layer1_0_bn2', 'add')],\n",
       " [('x', 0),\n",
       "  ('model_conv1', 9408),\n",
       "  ('model_bn1', 128),\n",
       "  ('model_relu', 0),\n",
       "  ('model_maxpool', 0),\n",
       "  ('model_layer1_0_conv1', 36864),\n",
       "  ('model_layer1_0_bn1', 128),\n",
       "  ('model_layer1_0_relu', 0),\n",
       "  ('model_layer1_0_conv2', 36864),\n",
       "  ('model_layer1_0_bn2', 128)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, weights, a, b = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f5ef1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting subset to evaulate mean\n",
    "edges, weights, a, b = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]\n",
    "\n",
    "\n",
    "\n",
    "train_dl_limit, _ = get_dataloaders([0,1,2,3,4,5,6,7], train_limit=256)# 256\n",
    "len(train_dl_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c6dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n"
     ]
    }
   ],
   "source": [
    "inter = {}\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('./model_last.ckpt', map_location='cpu'))\n",
    "tr = torch.fx.symbolic_trace(model)\n",
    "elem_count = 0\n",
    "for x,_ in train_dl_limit:\n",
    "    elem_count += x.shape[0]\n",
    "    i_ = get_inter(tr, x)\n",
    "    for k in i_:\n",
    "        try:\n",
    "            if k not in inter:\n",
    "                inter[str(k)] = i_[k].sum(0).detach()\n",
    "            else:\n",
    "                inter[str(k)] += i_[k].sum(0).detach()\n",
    "        except:\n",
    "            print ('bad inter', k)\n",
    "            #inter[str(k)] = 0.0\n",
    "    for k in inter:\n",
    "        inter[k] /= elem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba0fd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085d0e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fb0f4db3cc478298bf61e8918ea1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12.21679581142962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likelihood of the model without pruning\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('./model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "    \n",
    "full_ll = test_loop(model, train_dl_limit, nc=8, return_ll=True, device='cpu')\n",
    "full_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e33480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c7f9c0045d43ddbcc469472a14dd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0181b92beba041b0ab55e12208ebd43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443bf63ca8f647f9a498f8d307ceb603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1079cde49a464a3f9d3fec94450815af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43039ac68d1d4f658a0e718fd53391d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd794fc300478097df254dfaf27752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280956c1f46d434586b95b1abe88b6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1408661825594276921b344b13b9f503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c5658533254c1cbce6f579c82866a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103c83d4e15c496c905133682cf30044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cdf524f33d4a4fbf739ad8bd00ad09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4665a187a44e447e9050d64584e98652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675a1d482e4649f99fa7a88e6f430849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4ac40eb15d43bca873589ea6704042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d701fe8cb54e55913ba23e6c1d0593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc1ea6ea3904421a1eaf4c601733451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30871cf5c1c54d19a178d84868143004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8131bebf12a04cd3b29489376c3f1e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cd9eb341244854bae5940de8d9011d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0114291bc62c42a0b1c853139b23d3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b7995bd60b42cd8785755117d70612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9130b404f592427296b7e2fa44ce949f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9730735550ce48379b44bc7044af9214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da61d33d6ea947e79d418ce1443f9867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4262437d5453435283d27c7577892574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb7509bb3c742ff8c72d6027e26e11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3797be9cc6644319406c7d58a36997a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646f60b622514c629ea7e5c1534ae616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addf0e41af6d4867b8338fb5c25c07ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e32900df294aeea3c90c5e4a75b572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6137f878e54f9fa4400c72630e4f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4305b37eda6450793c28dfc5f5bd2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cf0303a6dd46b8bbbe817b7ff52306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a798d68d443129199163c1296af3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3efd948e384255a86006ab7fe275ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b980042e86354745801e95792103c3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9c8e64624f40b59fefb14edec07e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d6e5ca7ffe4f25a79f76de1b86f168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abbab04c2824cb887bf949f944d4687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f099a72fe36f47d393ecfe1a296bfd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbf7f17058a4f0989f3fd627d098a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ecedb1681e4c66a8abfaff3d7321d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee35d8f2ae24965a3ddcf3db1a4f396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4fe356477b480c9b004bf336379014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b6924c43c34710a2cc2f63c464f41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aaaf9afdbf4f11b89b4336622b9de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80b921310434846bf2db4bc9d0d13cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cd62bbfe9043cabd34557113eb8547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb11e0f10847c1ad8cba80ecd5c4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88905a32c25f4070a88000f6de18e842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d0aa842a2a498cacf36563adeb0af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d27c84166941b5856f5f95444da695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067d22b8877a431faa9abec1d7ff392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527f8382dfbd4d16a05cec30f53f7352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d54d1c3d5694dea9f9dcdba3e16a33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204d4f01770043709077624a26f5ee45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8ece1b6c514ddaa8850063b78e25aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c71a4f102a54b85932060045c51ca7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd8ef7db8a1463f8b840188e8e9d26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52895d36b6174408b09dd83bb9f1d708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6d28a521ce4ae0a89c1bb303f115c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff16a1e017f242ac8d63dc305e27068a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04537c315b746d48ee728412b161d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1494868521de40b88bdf6e74de821f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b639abefc91247f98351ec2495458241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfc55608b6f4e2eb23e5c3fcce07f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447def67f1df49d6a370b9cff0bbeb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbbe5cfd06042cfba15a8d3863f4c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e8809a974a404ca0d65f99d84a83ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d6d5fed8ac4eadbf171eb3fb263774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d18074c5c454a90a049d8a7851f5b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861ec76e6c7416bb932078c218c722b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb698a592d6d46f984fd851ba2cc79e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d22f207f8494fcc9acb952cf92b9a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df13e4d3f0094fceb2febd8f9378042a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635176b210f641f0bb93cfdc7daecfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a54d5e627ea4ac1a33008c67de59459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae4d0ae433f4fefa5658f15fe9327ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2aa4ecf80a46d3b1c965d3c166f778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ll for pruned models\n",
    "edge_ll = {}\n",
    "model = ResNet18(8)\n",
    "model.load_state_dict(torch.load('./model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "wrapped = torch.fx.symbolic_trace(model)\n",
    "    \n",
    "    \n",
    "for e in tqdm(edges):\n",
    "    pruned = PrunedModel(wrapped, {k:1.0 if k != e else 0.0 for k in edges }, inter)\n",
    "    edge_ll[e] = test_loop(pruned, train_dl_limit, nc=8, return_ll=True, device='cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dc56d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6867269778513567,\n",
       " 0.686726980815562,\n",
       " 0.7028506840060982,\n",
       " 0.7028506751134821,\n",
       " 0.5510818931627941,\n",
       " 0.5510818857522807,\n",
       " 0.22123894801958208,\n",
       " 0.22123894301748553,\n",
       " 0.2212389333838181,\n",
       " 0.2625129312717981,\n",
       " 0.637146508061444,\n",
       " 0.8549246308990748,\n",
       " 0.2700808469524391,\n",
       " 0.27008084398823373,\n",
       " 0.17254874674256804,\n",
       " 0.1725487485951964,\n",
       " 0.17254874896572206,\n",
       " 0.1660348703001716,\n",
       " 0.7709851022536136,\n",
       " 1.0,\n",
       " 0.5571379158972058,\n",
       " 0.5571379070045898,\n",
       " 0.334882749167205,\n",
       " 0.3348827462029997,\n",
       " 0.33488275657771843,\n",
       " 0.41678110673124735,\n",
       " 0.41678111562386344,\n",
       " 0.3447857561585027,\n",
       " 0.22906685804327434,\n",
       " 0.8587983671093765,\n",
       " 0.18137245321329376,\n",
       " 0.18137245469539645,\n",
       " 0.15517665322485003,\n",
       " 0.1551766526227458,\n",
       " 0.15517665512379408,\n",
       " 0.16542635710295725,\n",
       " 0.7857241984404829,\n",
       " 0.9755678692730418,\n",
       " 0.31775229364134494,\n",
       " 0.31775228771293423,\n",
       " 0.3061377500262021,\n",
       " 0.3061377485440994,\n",
       " 0.3061377478030481,\n",
       " 0.22559176262090913,\n",
       " 0.22559176484406315,\n",
       " 0.32042563339036484,\n",
       " 0.20896800280219377,\n",
       " 0.7659788498848801,\n",
       " 0.2378460777198877,\n",
       " 0.2378460814251444,\n",
       " 0.26770467842489076,\n",
       " 0.2677046762017367,\n",
       " 0.2677046754606854,\n",
       " 0.12471112521881839,\n",
       " 0.14263902461079525,\n",
       " 0.43110732023498016,\n",
       " 0.13493504375235296,\n",
       " 0.1349350415291989,\n",
       " 0.14193174279399157,\n",
       " 0.14193174594345975,\n",
       " 0.14193174520240842,\n",
       " 0.125609014147921,\n",
       " 0.1256090104426643,\n",
       " 0.13087626294638183,\n",
       " 0.1274445214358912,\n",
       " 0.44515513112455884,\n",
       " 0.142309804771447,\n",
       " 0.1423098032893443,\n",
       " 0.1243712716632502,\n",
       " 0.12437127129272452,\n",
       " 0.12437126981062184,\n",
       " 0.12689961693633356,\n",
       " 0.14242514052008204,\n",
       " 0.41448066253499516,\n",
       " 0.41448065364237907,\n",
       " 0.4144806714276113,\n",
       " 0.41448065364237907,\n",
       " 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't process logit edge, so setting its ll to min\n",
    "edge_ll[('model_fc', 'output')] = max(edge_ll.values())\n",
    "edges_importance = [edge_ll[e]/max(edge_ll.values()) for e in edges] #[1.0 - edge_ll[e]/max(edge_ll.values()) + EPS for e in edges]\n",
    "edges_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9592e369",
   "metadata": {},
   "source": [
    "<!-- ### Conclusion\n",
    "\n",
    "It seems that the problem is NP-hard. We need to come up with a new approach.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9a975",
   "metadata": {},
   "source": [
    "<!-- # The second attempt\n",
    "\n",
    "Consider the following heuristic\n",
    "\n",
    "1. Top sort (v_i, v_j) => i < j\n",
    "\n",
    "2. for k in {n, ..., 1}\n",
    "\n",
    "Consider 2 cases:\n",
    "\n",
    "a) put v_k into the layer of its nearest child + prune some edges\n",
    "\n",
    "b) put vk into a new layer => \n",
    "\n",
    "Consider all subsets of outcoming edges. We instantly identify a layer given a subset. So, we aggregate this layer with the answer of the nearest child to v_k\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cac8f",
   "metadata": {},
   "source": [
    "## The second attempt + deleting of edges\n",
    "\n",
    "1. Find all (sample) topological sorts\n",
    "\n",
    "https://www.geeksforgeeks.org/all-topological-sorts-of-a-directed-acyclic-graph/\n",
    "\n",
    "2. Apply greedy dynamic programming to find a monotonous solution\n",
    "\n",
    "3. Postprocess a graph: remove all nodes that are unreacheble from \"x\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f23f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legin/.local/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9261"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG = nx.DiGraph(edges)\n",
    "all_sorts = list(nx.all_topological_sorts(DG))\n",
    "len(all_sorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68ea91bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 78)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges), len(edges_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1813ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def dp_for_top_sort(edges, weights, e_importance, top_sort_str, memory=1e10):\n",
    "    node_ids = {k: i for i, k in enumerate(weights)}\n",
    "    id_to_node = [node for _, node in enumerate(weights)]\n",
    "    top_sort = np.array([node_ids[n] for n in top_sort_str])\n",
    "    assert top_sort[-1] == node_ids['output']\n",
    "    assert top_sort[0] == node_ids['x']\n",
    "    assert top_sort.shape[0] == len(node_ids)\n",
    "    m = np.zeros((len(node_ids), len(node_ids))).astype(np.int32)\n",
    "    id_to_weight = np.array([weights[n] for n in id_to_node])\n",
    "    assert len(edges) == len(e_importance)\n",
    "    for (src, dst), w in zip(edges, e_importance):\n",
    "        src_id, dst_id = node_ids[src], node_ids[dst]\n",
    "        m[src_id, dst_id] = w\n",
    "        \n",
    "    node_to_layers = np.ones((len(node_ids), len(node_ids))).astype(np.int32) * (-100)  # ans for each v ->\n",
    "    node_to_layers[top_sort[-1], top_sort[-1]] = 0\n",
    "    dp = [1e9] * len(node_ids)\n",
    "    dp[top_sort[-1]] = 0\n",
    "    for i in range(len(node_ids) - 2, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        for j in range(i, len(node_ids)):  # the last node of the first layer (starting from v)\n",
    "            if id_to_weight[top_sort[i: j + 1]].sum() > memory:\n",
    "                continue\n",
    "            if j == len(node_ids) - 1:\n",
    "                dp[v] = 0\n",
    "                node_to_layers[v, top_sort[i:]] = 0\n",
    "                continue\n",
    "            v_j = top_sort[j + 1]\n",
    "            next_layer_ids = [] if j + 1 >= len(node_ids) else \\\n",
    "            [k for k in range(m.shape[0]) if node_to_layers[v_j, k] == node_to_layers[v_j, v_j]]\n",
    "            pruned_value = sum([m[top_sort[k], l] for k in range(i, j + 1) for l in next_layer_ids if m[top_sort[k], l] != 0])\n",
    "            if dp[v_j] + pruned_value <= dp[v]:\n",
    "                dp[v] = dp[v_j] + pruned_value\n",
    "                node_to_layers[v] = node_to_layers[v_j]\n",
    "                node_to_layers[v, top_sort[i:j + 1]] = node_to_layers[v].max() + 1\n",
    "                \n",
    "    # prune restricted edges (TODO: also prune unreacheble nodes)\n",
    "    ans = node_to_layers[node_ids['x']]\n",
    "    pruned_edges_ids = [(i, j) for i in range(m.shape[0]) for j in range(m.shape[0]) \\\n",
    "                    if m[i, j] != 0 and abs(ans[i] - ans[j]) > 1]\n",
    "    pruned_edges = [(id_to_node[i], id_to_node[j]) for i, j in pruned_edges_ids]\n",
    "    pruned_value = sum([m[i, j] for i, j in pruned_edges_ids])\n",
    "    \n",
    "    reach_ids = [set() for _ in range(len(node_ids))]\n",
    "    for i in range(len(node_ids) - 1, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        reach_ids[v].add(v)\n",
    "        for k in range(i + 1, m.shape[0]):\n",
    "            v_c = top_sort[k]\n",
    "            if m[v, v_c] != 0 and (v, v_c) not in pruned_edges_ids:\n",
    "                reach_ids[v] |= reach_ids[v_c]\n",
    "    conn_g = top_sort[-1] in reach_ids[top_sort[0]]\n",
    "                \n",
    "    return {'node_to_layer': {id_to_node[i]: ans.max() - l for i, l in enumerate(ans)},\n",
    "            'pruned_value': pruned_value, 'pruned_edges': pruned_edges,\n",
    "            'connected_graph': conn_g}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94affd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32632d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f0a1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642946a81e764bb4a4646574ca02cff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e128c82bda1444c984cb0659cd2610f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7f2ebde7a0485386be9e7bb4932f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772b4f449f2742aa8c2302b20872f6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa9825ee1c48ac8075569c77576711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4276b5a5d7c4ab399096836ab006ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6530532ef6b41e5b034ed455272f630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9634739dbed4c4dacdc1535ea8becff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c24c36359a4643af3bab3250e73c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/legin/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3610e541d9314ec4b626609af7d00a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d8a23112a14272aeeec0dd68f69890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1637822933ab49b081fe898316ad1f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### find the best solution\n",
    "import pickle\n",
    "with open('./naive_mean.pckl', 'rb') as inp:\n",
    "    eval_dict, fine_dict = pickle.loads(inp.read())\n",
    "#eval_dict = {}\n",
    "#fine_dict = {}\n",
    "\n",
    "for edge_mem in range(2,6):\n",
    "    if edge_mem in eval_dict and edge_mem in fine_dict:\n",
    "        print ('skip', edge_mem)\n",
    "        continue\n",
    "    #if edge_mem == 3 and attemp > 0:\n",
    "    #    continue\n",
    "    #if edge_mem == 4 and attemp > 0:\n",
    "    #    continue\n",
    "\n",
    "    model = ResNet18(8)\n",
    "    model.load_state_dict(torch.load('./model_last.ckpt', map_location='cpu'))\n",
    "    warp = GraphInterperterWithGamma(model)\n",
    "\n",
    "    named_dict = dict(model.named_modules())\n",
    "\n",
    "    for node in warp.graph.nodes:\n",
    "        if node.op == 'call_module':\n",
    "            pass\n",
    "            # print('Norm', np.sqrt(sum([(p ** 2).sum().item() \\\n",
    "            #                            for p in named_dict[node.target].parameters()])))\n",
    "        # print(node.op, node.name, node.args)\n",
    "        # break\n",
    "\n",
    "\n",
    "    edges, weights, a, b = module_to_graph(ResNet18())\n",
    "    # edges, weights\n",
    "    edges[:10], list(weights.items())[:10]\n",
    "    edges_importance = [1]*len(edges)\n",
    "\n",
    "    best_pruned = 1e10\n",
    "    best_val = None\n",
    "    for s in tqdm(all_sorts):\n",
    "        # for mem=8 the computation takes time\n",
    "        res = dp_for_top_sort(edges, {k: 1 for k in weights}, edges_importance, s, edge_mem)  \n",
    "        if res['connected_graph'] == True and best_pruned > res['pruned_value']:\n",
    "            best_pruned = res['pruned_value']\n",
    "            best_val = res\n",
    "\n",
    "        if best_pruned == 0:\n",
    "            print(res)\n",
    "            break\n",
    "\n",
    "\n",
    "    model = ResNet18(8)\n",
    "    model.load_state_dict(torch.load('./model_last.ckpt', map_location='cpu'))\n",
    "\n",
    "    wrapped = torch.fx.symbolic_trace(model)\n",
    "    pruned = PrunedModel(wrapped, {k:1.0 if k not in best_val['pruned_edges'] else 0.0 for k in edges }, inter)\n",
    "\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "    if edge_mem not in eval_dict:\n",
    "        eval_dict[edge_mem] = []\n",
    "    eval_dict[edge_mem].append(res)\n",
    "\n",
    "    train_loop(pruned, train_dl, test_dl, 9999999999, 1, 1e-3,  \"cpu\")\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "    if edge_mem not in fine_dict:\n",
    "        fine_dict[edge_mem] = []\n",
    "    fine_dict[edge_mem].append(res)\n",
    "\n",
    "    import pickle\n",
    "    with open('naive_mean.pckl', 'wb') as out:\n",
    "        out.write(pickle.dumps([eval_dict, fine_dict]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73532c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b9a69a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ac5888c94b4757ae0a6adc6649c3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731f6bd97e7547d69c9bc9ad188f6834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if edge_mem not in eval_dict:\n",
    "    eval_dict[edge_mem] = []\n",
    "eval_dict[edge_mem].append(res)\n",
    "\n",
    "train_loop(pruned, train_dl, test_dl, 9999999999, 1, 1e-3,  \"cpu\")\n",
    "res = test_loop(pruned, test_dl,  \"cpu\", nc=8)\n",
    "if edge_mem not in fine_dict:\n",
    "    fine_dict[edge_mem] = []\n",
    "fine_dict[edge_mem].append(res)\n",
    "\n",
    "import pickle\n",
    "with open('naive.pckl', 'wb') as out:\n",
    "    out.write(pickle.dumps([eval_dict, fine_dict]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee91dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125], 3: [0.125], 4: [0.12524999678134918], 5: [0.23675000667572021]},\n",
       " {2: [0.5216249823570251],\n",
       "  3: [0.5532500147819519],\n",
       "  4: [0.656624972820282],\n",
       "  5: [0.6958749890327454]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('naive.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11b325a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125, 0.12600000202655792, 0.125],\n",
       "  3: [0.125, 0.125, 0.125],\n",
       "  4: [0.12524999678134918, 0.12524999678134918, 0.125],\n",
       "  5: [0.1368750035762787, 0.125, 0.21812500059604645]},\n",
       " {2: [0.5640000104904175, 0.5180000066757202, 0.5730000138282776],\n",
       "  3: [0.5625, 0.5435000061988831, 0.5742499828338623],\n",
       "  4: [0.6353750228881836, 0.6573749780654907, 0.6784999966621399],\n",
       "  5: [0.6420000195503235, 0.6677500009536743, 0.6775000095367432]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('randn.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "361d4743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.125], 3: [0.125], 4: [0.1264999955892563], 5: [0.2516250014305115]},\n",
       " {2: [0.5951250195503235],\n",
       "  3: [0.6156250238418579],\n",
       "  4: [0.6588749885559082],\n",
       "  5: [0.6837499737739563]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('naive_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ea4825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.12962499260902405, 0.125, 0.125],\n",
       "  3: [0.125, 0.125, 0.125],\n",
       "  4: [0.12612499296665192, 0.12612499296665192, 0.125],\n",
       "  5: [0.12587499618530273, 0.12587499618530273]},\n",
       " {2: [0.5892500281333923, 0.5241249799728394, 0.6132500171661377],\n",
       "  3: [0.5706250071525574, 0.6041250228881836, 0.5644999742507935],\n",
       "  4: [0.6047499775886536, 0.6507499814033508, 0.6359999775886536],\n",
       "  5: [0.6508749723434448, 0.6942499876022339]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('random_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
