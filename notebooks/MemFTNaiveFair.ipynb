{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ff391e-d313-445d-8c54-3b1b4f4d6ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "from src.module2graph import GraphInterperterWithGamma\n",
    "from src.resnet18 import ResNet18\n",
    "import numpy as np\n",
    "\n",
    "import graphviz\n",
    "import itertools\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple, Dict # actually we don't need it for py>=3.9, but I have 3.8 on my laptop\n",
    "from src.utils import train_loop, test_loop\n",
    "from src.cifar_data import get_dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c2ff15-a75e-4935-9ed0-9ed32e8f43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12aa2a5-09e6-44a2-8aa1-005df1b30134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! unzip tiny-imagenet-200.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51345bb-90a9-4ce8-912f-b1cfd7edb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"tiny-imagenet-200/\"\n",
    "# num_workers = {\"train\": 2, \"val\": 0, \"test\": 0}\n",
    "# data_transforms = {\n",
    "#     \"train\": transforms.Compose(\n",
    "#         [\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "#         ]\n",
    "#     ),\n",
    "#     \"val\": transforms.Compose(\n",
    "#         [\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "#         ]\n",
    "#     ),\n",
    "# }\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "#                                           data_transforms[x]) for x in [\"train\", \"val\"]}\n",
    "# dataloaders = {\n",
    "#     x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
    "#                                    shuffle=True, num_workers=num_workers[x])\n",
    "#     for x in [\"train\", \"val\"]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50300a5a-bf9a-458b-b14b-b604a452b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cls = [0, 1]\n",
    "train_dl, test_dl = get_dataloaders(classes=cls, batch_size=64,\n",
    "                                   img_size=33, cifar100=False)\n",
    "\n",
    "# Tiny-Imagenet\n",
    "# train_dl, test_dl = dataloaders['train'], dataloaders['val']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbdcaa2-6b2e-4e25-9a05-b25b323d41e1",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "1. Fine-tune the last layer of the pretrained ResNet18 on Imagenet\n",
    "2. Calculate the importance of each edge in a neive way (directly estimate the loss increment)\n",
    "instead of fine-tuning the whole model first, since it contradicts to the protocol of our experimental section (we can't fine-tune the whole model due to the lack of GPU memory).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2621f18a-a8f8-421b-8687-44d56dbd593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(num_classes=len(cls)) # attention\n",
    "for n, p in model.named_parameters():\n",
    "    if 'fc' not in n:\n",
    "        p.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam([p for n, p in model.named_parameters() if 'fc' in n],\n",
    "                           lr=1e-3)\n",
    "crit = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b321e3-c2db-4074-8abb-cfd248a258fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba5c080107244eab43dcc83a0250c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dfae9e83d64c54998d45f063eb9d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1d3470d6d14a0ab5859ec7bde27b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd88eb3f0a94aab838ec57fd58f4681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8c8ec6956540ca9f38f766ad5de66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4226d88de41745eda6757875987cb324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59324b6342234ca0b3391a2586152dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5f7361747e468798b12891a79c4aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ad50f81b9b48399e259d4bdaccaf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aacd53300344460912f4e464ac96314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9235\n"
     ]
    }
   ],
   "source": [
    "device = 'mps'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for epoch in range(10):\n",
    "    # model.train() # no need to switch to training mode\n",
    "    for i ,(x, y) in enumerate(tqdm(train_dl)):\n",
    "        logits = model(x.to(device))[0]\n",
    "        loss = crit(logits, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            n_corr = 0\n",
    "            n_tot = 0\n",
    "            model.eval()\n",
    "            for j, (x, y) in enumerate(test_dl):\n",
    "                with torch.inference_mode():\n",
    "                    logits = model(x.to(device))[0]\n",
    "                    n_corr += (logits.argmax(-1) == y.to(device)).sum().item()\n",
    "                    n_tot += x.shape[0]\n",
    "                if j >= 50:\n",
    "                    break\n",
    "            print(n_corr / n_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34fc4f62-6b0d-4651-96ae-bd41cd4c73a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e10e0f4ffd848ff8f57bc4a706226cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065\n"
     ]
    }
   ],
   "source": [
    "n_corr = 0\n",
    "n_tot = 0\n",
    "model.eval()\n",
    "for j, (x, y) in enumerate(tqdm(test_dl)):\n",
    "    with torch.inference_mode():\n",
    "        logits = model(x.to(device))[0]\n",
    "        n_corr += (logits.argmax(-1) == y.to(device)).sum().item()\n",
    "        n_tot += x.shape[0]\n",
    "print(n_corr / n_tot)\n",
    "torch.save(model.model.fc.state_dict(), 'fc_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cdafa80-6855-40e9-b8b6-4da6c1fa575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d68a54-d356-4573-ad0a-7cecae8ab6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward for target model with gamma values for each edge.\n",
    "# means - mean values for arguments\n",
    "def forward_with_gammas(model, gammas: Dict[Tuple[str, str], torch.Tensor], \n",
    "                        means: Dict[str, torch.Tensor] = None, *torch_model_args):\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "            gammas_node = [int(gammas[e])  if (e is not None) else 1 for e in edges ]\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g  for a0,a,g in zip(node.args,\n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            #print (len(args), len(node.args))\n",
    "            #print (node, [a for a in node.args])\n",
    "            #print (node, [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            args =  [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args[1:], \n",
    "                                                                        args, gammas_node)]\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = [a*g + (1.0 - g) * means[str(a0)] if str(a0) in means else a*g   for a0, a,g in zip(node.args, \n",
    "                                                                           load_arg(node.args), gammas_node)]\n",
    "            \n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "            \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return result, env # currently ignorign means for output\n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return result\n",
    "\n",
    "# a wrapper that takes model and uses forward_with_Gammas\n",
    "class PrunedModel(torch.nn.Module):\n",
    "    def __init__(self, base, prune_dict, means = None):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.prune_dict = prune_dict\n",
    "        self.means = means \n",
    "    def forward(self, x):\n",
    "        return forward_with_gammas(self.base, self.prune_dict,  self.means, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87bf2c67-8baa-4c1a-85d3-b7039469dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets intermediate representations of nodes\n",
    "def get_inter(model, *torch_model_args) -> dict:\n",
    "    args_iter = iter(torch_model_args)\n",
    "    env : Dict[str, Node] = {}\n",
    "    used_edges = set()\n",
    "    inter = {}\n",
    "    def load_arg(a):    \n",
    "        return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n",
    "\n",
    "    def fetch_attr(target : str):\n",
    "        target_atoms = target.split('.')\n",
    "        attr_itr = model.graph\n",
    "        for i, atom in enumerate(target_atoms):\n",
    "            if not hasattr(attr_itr, atom):\n",
    "                raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n",
    "            attr_itr = getattr(attr_itr, atom)\n",
    "        return attr_itr\n",
    "    named_modules = dict(model.named_modules())\n",
    "    for node in model.graph.nodes:\n",
    "        edges = []\n",
    "\n",
    "        if node.op in ['call_module', 'call_function', 'output']:    \n",
    "            if node.op == 'output':\n",
    "                edges = [(node.args[0][0].name, node.name)]\n",
    "            else:\n",
    "    \n",
    "                for arg in node.args:\n",
    "                    if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                        edges.append((arg.name, node.name))\n",
    "                    else:\n",
    "                        edges.append(None)\n",
    "                \n",
    "            #print (edges, gammas_node)\n",
    "        if node.op == 'placeholder':\n",
    "            result = next(args_iter) \n",
    "        elif node.op == 'get_attr':\n",
    "            result = fetch_attr(node.target)\n",
    "        elif node.op == 'call_function':\n",
    "            \n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            #print (len(args), len(node.args))\n",
    "            #print ([a.shape for a in load_arg(node.args)], [a.shape for a in args])\n",
    "            result = node.target(*args, **load_arg(node.kwargs)) \n",
    "        elif node.op == 'call_method':\n",
    "            self_obj, *args = load_arg(node.args) \n",
    "            \n",
    "            for a_, a in zip(node.args[1:], args):\n",
    "                inter[a_] = a\n",
    "            kwargs = load_arg(node.kwargs)\n",
    "            result = getattr(self_obj, node.target)(*args, **kwargs)\n",
    "        elif node.op == 'call_module':\n",
    "            args = load_arg(node.args)\n",
    "            for a_, a in zip(node.args, args):\n",
    "                inter[a_] = a\n",
    "            result = named_modules[node.target](*args, **load_arg(node.kwargs)) \n",
    "        \n",
    "        \n",
    "        result = result\n",
    "        for e in edges:\n",
    "            used_edges.add(e)\n",
    "    \n",
    "        if node.op == 'output':\n",
    "            \n",
    "            return inter \n",
    "        #print (node.args, node.name, node.op, abs(result).sum().item())\n",
    "        env[node.name] = result\n",
    "        \n",
    "    return inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f1d6775-3861-427e-9393-25e487a6366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "\n",
    "def module_to_graph(m: torch.nn.Module):\n",
    "    graph = torch.fx.symbolic_trace(m).graph\n",
    "    named_dict = dict(m.named_modules())\n",
    "    edges = [] # (from, to)\n",
    "    grad = {'x': 0}\n",
    "    params = {'x': 0}\n",
    "    weights = {'x': 0} # node: params\n",
    "    means = {}\n",
    "    for node in graph.nodes:\n",
    "    \n",
    "        # no placeholder and call_mathod\n",
    "        if node.op == 'call_module':\n",
    "            n_params = 0\n",
    "            grad_1 = []\n",
    "            params_1 = []\n",
    "            for p in named_dict[node.target].parameters():\n",
    "                n_params += p.numel()\n",
    "                grad_1.append(p.grad)\n",
    "                params_1.append(p)\n",
    "            try:\n",
    "                grad[node.name] = torch.mean(torch.stack(grad_1))\n",
    "                params[node.name] = torch.mean(torch.stack(params_1))\n",
    "            except:\n",
    "                grad[node.name] = 0\n",
    "                params[node.name] = 0\n",
    "            weights[node.name] = n_params\n",
    "            assert len(node.args) == 1\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "        elif node.op == 'call_function':\n",
    "            for arg in node.args:\n",
    "                if type(arg) == torch.fx.Node:  # ignore constants\n",
    "                    edges.append((arg.name, node.name))\n",
    "            weights[node.name] = 0\n",
    "        elif node.op == 'output':\n",
    "            try:\n",
    "                edges.append((node.args[0][0].name, node.name))\n",
    "            except:\n",
    "                edges.append((node.args[0].name, node.name))\n",
    "            weights['output'] = 0\n",
    "        \n",
    "        #if  len(edges)>0 and edges[-1] == ('model_maxpool', 'add'):\n",
    "        #    print (node.args, node.name, node.op)\n",
    "    return edges, {'_'.join(k.split('.')): v for k, v in weights.items()}, {'_'.join(k.split('.')): v for k, v in params.items()}, {'_'.join(k.split('.')): v for k, v in grad.items()}\n",
    "\n",
    "module_to_graph(model)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56b98432-b72d-403c-9f82-5c61b628903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('x', 'model_conv1'),\n",
       "  ('model_conv1', 'model_bn1'),\n",
       "  ('model_bn1', 'model_relu'),\n",
       "  ('model_relu', 'model_maxpool'),\n",
       "  ('model_maxpool', 'model_layer1_0_conv1'),\n",
       "  ('model_layer1_0_conv1', 'model_layer1_0_bn1'),\n",
       "  ('model_layer1_0_bn1', 'model_layer1_0_relu'),\n",
       "  ('model_layer1_0_relu', 'model_layer1_0_conv2'),\n",
       "  ('model_layer1_0_conv2', 'model_layer1_0_bn2'),\n",
       "  ('model_layer1_0_bn2', 'add')],\n",
       " [('x', 0),\n",
       "  ('model_conv1', 9408),\n",
       "  ('model_bn1', 128),\n",
       "  ('model_relu', 0),\n",
       "  ('model_maxpool', 0),\n",
       "  ('model_layer1_0_conv1', 36864),\n",
       "  ('model_layer1_0_bn1', 128),\n",
       "  ('model_layer1_0_relu', 0),\n",
       "  ('model_layer1_0_conv2', 36864),\n",
       "  ('model_layer1_0_bn2', 128)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, weights, a, b = module_to_graph(ResNet18())\n",
    "# edges, weights\n",
    "edges[:10], list(weights.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26fb588d-4f48-479b-a7a9-857c1487f89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9993ac6935d24ced9ac0c2191b624b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.906499981880188"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likelihood/accuracy of the original model\n",
    "full_ll = test_loop(model, test_dl, nc=len(cls), return_ll=False, device='cpu')\n",
    "full_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c86c0d-446e-4541-b08b-0bcd720bb687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n",
      "bad inter 1\n"
     ]
    }
   ],
   "source": [
    "inter = {}\n",
    "# TODO:fix an issue with all bad iter when dealing with test split\n",
    "train_dl_limit, _ = get_dataloaders(cls, train_limit=256)\n",
    "tr = torch.fx.symbolic_trace(ResNet18(2))\n",
    "elem_count = 0\n",
    "for x,_ in train_dl_limit:\n",
    "    elem_count += x.shape[0]\n",
    "    i_ = get_inter(tr, x)\n",
    "    for k in i_:\n",
    "        try:\n",
    "            if k not in inter:\n",
    "                inter[str(k)] = i_[k].sum(0).detach()\n",
    "            else:\n",
    "                inter[str(k)] += i_[k].sum(0).detach()\n",
    "        except:\n",
    "            print ('bad inter', k)\n",
    "            #inter[str(k)] = 0.0\n",
    "    for k in inter:\n",
    "        inter[k] /= elem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36fb8bc3-75c6-42f2-adba-8fa48f74e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/pytorch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8868ae6b8443a2a0f5d91ad5eee116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016978fbe6894bd89239cce26f3b8b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cc4effe6a44c2eb5b513e0cf65c223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec199f375609452d95c8c17ac64ecb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865aa7e2400342af9cf38dc94d5cc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25046c1647c473cad5a2fddeed21eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a100111c9e44e19f51aaf0920b62bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a45f340009b41d4b363fd35bd3c4722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29895052093b4c6cb4cb457fad597975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153423858078488baeeb228c359b8b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2db882ef24a4049b708d7617311f882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8e7e0c86944139a2767dcb161f5e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c376ba31dce64a19afe5c18da17a3e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a347585e4a447dac73a913f6940d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f75a88ed4c64acab40e58e030e89b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9037da4e771c470f80b01e3a76b1aacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0b62cd26ae4ecb868bf559b8a2e2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6543c4e048f4b0ab165413f84eeb273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1aa66977f9043be809d796d9cbf627d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbce61ea19574479b63128fd2f6e8cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c35474bf2e544cebba1c3d16e5a4733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18531afdfc9a4c0ca0a99d192687507b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aa0a55889d4941bac19f56712b43fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1783946d86243aa83806d8f68ab23cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc9c1033cd943709657881fcda4948c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd15807b776a4dfbb4782dd19aa04a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fd6931df7e481a84e304dde9b04927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f916c3310c4a5c8cbf2decf464d3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592c2cfda408448e8ce03ea218628e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2455a81c214eb2a8c86f76206d7c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3d25e0ed1342c29b907ae2b13d24fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafe93adbc9d47eaa225099f2fd09fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e5adc2b7d1431391dff5b3d1f322bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320d97c8dc8c423fa26326041c7b3ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d292140de134c1e8b553496ad59a9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3213ddd2934d24960ae19a968da2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0aedb516fb246099fefd11f58c7183c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97b028f1ee74765a71ef3fedae2f227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a381fc6ab0c2472cabe304e0bad92174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e993bb565734ff89a1749d68c8a892a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723f529eabe64655bc9b663445676bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc0d0af5ea2475290f2d1e4cf56cca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1de1e19b414cfca6a2c5fed66b9f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d95f6147cd43aa83b47ca033e4b412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc0c19b67a741b5ac1c078ce852d539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828086c5ed6949b38ff313ee43b3f90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91282fc44eee48ce848410c2f43a872e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e55dd014b174ee683c536a7e9d0ac76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2791c6998df409fb391a06ed5af02a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c16724189544a0960a4caa2793657d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b21e33b9ba424e880b8f46da140275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd67613a9a04131ab1ae223b0379145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50170c7d04b9433392e8d5c4d86c7d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1f56dfd1d44a6fbbd07dc452e8987c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddb4ce814544e878ebc0a90943d5c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8229e22c1bed4883b65fbd737014d1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a439a981dc41b8a7bc03246c0323d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683f43aa69294b6d97849cdb305cd2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45249b100f7941dbbe9cda28e0e05932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa54f1ae239b4c4c991348de0baf019f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce5fba574c64640adf332665ffc1f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86267bea2e2e40a58910097f271b6b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec49e05a90648589af5749c723f57f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab62343d7ec4b19ba01d371755c716c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686bb6ebe29748c79b16850e9ca950a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d816e1f60d8489ea34547a1f7226107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c47dc307d9340cf8b125331a076600c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2496e0aa7494900bc4e592ef2e5ea44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28da0cd0d4b74c23a32c4e1017eaaa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce191b47810e4686b68bcd3af49e6efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693982be8e014e9792fc1a53772a1850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856d3ffaecce49879e074147e5c9a723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c5e87937cd43b89805e77b1333ef4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfbcc4753814333a47c37466bc33e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4ebe1c8f1340a88cc72a5992ff8b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1423dcfdfbca4ab199416db5cb13d47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed44a8dd22146c69c7f8471f6cdae6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17f0a817b5e4d7780f0f71f9008196d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7911e585a6c148e5a1b481ba4938fa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ll for pruned models (naively)\n",
    "edge_ll = {}\n",
    "model = ResNet18(2)\n",
    "model.model.fc.load_state_dict(torch.load('fc_best.ckpt', map_location='cpu'))\n",
    "wrapped = torch.fx.symbolic_trace(model)\n",
    "    \n",
    "for e in tqdm(edges):\n",
    "    pruned = PrunedModel(wrapped, {k:1.0 if k != e else 0.0 for k in edges}, inter)\n",
    "    # edge_ll[e] = test_loop(pruned, train_dl_limit, nc=2, return_ll=True, device='cpu')\n",
    "    edge_ll[e] = test_loop(pruned, test_dl, nc=2, return_ll=False, device='cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87646f02-54d5-4b79-af54-b16cffdc5ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4721455949832417,\n",
       " 0.4721455949832417,\n",
       " 0.4721455949832417,\n",
       " 0.4721455949832417,\n",
       " 0.4721455949832417,\n",
       " 0.4721455949832417,\n",
       " 0.16822942837533583,\n",
       " 0.16822942837533583,\n",
       " 0.16822942837533583,\n",
       " 0.1108659565483775]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't process logit edge, so setting its ll to min\n",
    "edge_ll[('model_fc', 'output')] = max(edge_ll.values())\n",
    "# edges_importance = [edge_ll[e]/max(edge_ll.values()) for e in edges]\n",
    "edges_importance = [-edge_ll[e] / full_ll for e in edges]\n",
    "edges_importance = [imp - min(edges_importance) for imp in edges_importance]\n",
    "\n",
    "edges_importance[:10]\n",
    "# {e : -edge_ll[e] / full_ll for e in edges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16a735ec-aaff-4af0-9c18-1bf0b4cd7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "352eaa7a-76fe-4879-9d36-b69758614cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9261"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG = nx.DiGraph(edges)\n",
    "all_sorts = list(nx.all_topological_sorts(DG))\n",
    "len(all_sorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77935a3d-9c71-4902-aed1-0238bf0e7c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 78)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges), len(edges_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5065e8f0-148d-4b00-9139-4e938bff258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def dp_for_top_sort(edges, weights, e_importance, top_sort_str, memory=1e10):\n",
    "    node_ids = {k: i for i, k in enumerate(weights)}\n",
    "    id_to_node = [node for _, node in enumerate(weights)]\n",
    "    top_sort = np.array([node_ids[n] for n in top_sort_str])\n",
    "    assert top_sort[-1] == node_ids['output']\n",
    "    assert top_sort[0] == node_ids['x']\n",
    "    assert top_sort.shape[0] == len(node_ids)\n",
    "    m = np.zeros((len(node_ids), len(node_ids))).astype(np.int32)\n",
    "    id_to_weight = np.array([weights[n] for n in id_to_node])\n",
    "    assert len(edges) == len(e_importance)\n",
    "    for (src, dst), w in zip(edges, e_importance):\n",
    "        src_id, dst_id = node_ids[src], node_ids[dst]\n",
    "        m[src_id, dst_id] = w\n",
    "        \n",
    "    node_to_layers = np.ones((len(node_ids), len(node_ids))).astype(np.int32) * (-100)  # ans for each v ->\n",
    "    node_to_layers[top_sort[-1], top_sort[-1]] = 0\n",
    "    dp = [1e9] * len(node_ids)\n",
    "    dp[top_sort[-1]] = 0\n",
    "    for i in range(len(node_ids) - 2, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        for j in range(i, len(node_ids)):  # the last node of the first layer (starting from v)\n",
    "            if id_to_weight[top_sort[i: j + 1]].sum() > memory:\n",
    "                continue\n",
    "            if j == len(node_ids) - 1:\n",
    "                dp[v] = 0\n",
    "                node_to_layers[v, top_sort[i:]] = 0\n",
    "                continue\n",
    "            v_j = top_sort[j + 1]\n",
    "            next_layer_ids = [] if j + 1 >= len(node_ids) else \\\n",
    "            [k for k in range(m.shape[0]) if node_to_layers[v_j, k] == node_to_layers[v_j, v_j]]\n",
    "            pruned_value = sum([m[top_sort[k], l] for k in range(i, j + 1) for l in next_layer_ids if m[top_sort[k], l] != 0])\n",
    "            if dp[v_j] + pruned_value <= dp[v]:\n",
    "                dp[v] = dp[v_j] + pruned_value\n",
    "                node_to_layers[v] = node_to_layers[v_j]\n",
    "                node_to_layers[v, top_sort[i:j + 1]] = node_to_layers[v].max() + 1\n",
    "                \n",
    "    # prune restricted edges (TODO: also prune unreacheble nodes)\n",
    "    ans = node_to_layers[node_ids['x']]\n",
    "    pruned_edges_ids = [(i, j) for i in range(m.shape[0]) for j in range(m.shape[0]) \\\n",
    "                    if m[i, j] != 0 and abs(ans[i] - ans[j]) > 1]\n",
    "    pruned_edges = [(id_to_node[i], id_to_node[j]) for i, j in pruned_edges_ids]\n",
    "    pruned_value = sum([m[i, j] for i, j in pruned_edges_ids])\n",
    "    \n",
    "    reach_ids = [set() for _ in range(len(node_ids))]\n",
    "    for i in range(len(node_ids) - 1, -1, -1):\n",
    "        v = top_sort[i]\n",
    "        reach_ids[v].add(v)\n",
    "        for k in range(i + 1, m.shape[0]):\n",
    "            v_c = top_sort[k]\n",
    "            if m[v, v_c] != 0 and (v, v_c) not in pruned_edges_ids:\n",
    "                reach_ids[v] |= reach_ids[v_c]\n",
    "    conn_g = top_sort[-1] in reach_ids[top_sort[0]]\n",
    "                \n",
    "    return {'node_to_layer': {id_to_node[i]: ans.max() - l for i, l in enumerate(ans)},\n",
    "            'pruned_value': pruned_value, 'pruned_edges': pruned_edges,\n",
    "            'connected_graph': conn_g}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f95e4cc-f7a5-495a-b695-22e7ba719f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.16822942837533583, 0.16822942837533583, 0.16822942837533583, 0.1108659565483775, 0.4478764110651998, 0.4721455949832417, 0.3673468850999958, 0.3673468850999958, 0.12465524317709276, 0.12465524317709276, 0.12465524317709276, 0.05681187406080768, 0.4120242658305403, 0.4721455949832417, 0.4495311386111467, 0.4495311386111467, 0.24875895434053985, 0.24875895434053985, 0.24875895434053985, 0.3314947398653363, 0.3314947398653363, 0.12300051563114589, 0.3083286857270906, 0.4721455949832417, 0.15499167376026612, 0.15499167376026612, 0.2471042267945931, 0.2471042267945931, 0.2471042267945931, 0.10921122900243063, 0.4660782825656049, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0, 0.0, 0.3182569852502666, 0.001103129779796319, 0.4721455949832417, 0.2504136818864867, 0.2504136818864867, 0.012134559082768392, 0.012134559082768392, 0.012134559082768392, 0.023717586151891235, 0.4649751527858088, 0.4721455949832417, 0.29453939909837545, 0.29453939909837545, 0.2818532422494564, 0.2818532422494564, 0.2818532422494564, 0.07170435622182425, 0.07170435622182425, 0.061776056698648274, 0.1047986441307408, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.44401542395966065, 0.44401542395966065, 0.44401542395966065, 0.07391061578141667, 0.020408131059997503, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5aba2bbe1646ef823fc01b6bd968f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f624c792fc1246db9f1e7a224b38f2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3eaa5fe38b44f7a5257aaa86bd6415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.16822942837533583, 0.16822942837533583, 0.16822942837533583, 0.1108659565483775, 0.4478764110651998, 0.4721455949832417, 0.3673468850999958, 0.3673468850999958, 0.12465524317709276, 0.12465524317709276, 0.12465524317709276, 0.05681187406080768, 0.4120242658305403, 0.4721455949832417, 0.4495311386111467, 0.4495311386111467, 0.24875895434053985, 0.24875895434053985, 0.24875895434053985, 0.3314947398653363, 0.3314947398653363, 0.12300051563114589, 0.3083286857270906, 0.4721455949832417, 0.15499167376026612, 0.15499167376026612, 0.2471042267945931, 0.2471042267945931, 0.2471042267945931, 0.10921122900243063, 0.4660782825656049, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0, 0.0, 0.3182569852502666, 0.001103129779796319, 0.4721455949832417, 0.2504136818864867, 0.2504136818864867, 0.012134559082768392, 0.012134559082768392, 0.012134559082768392, 0.023717586151891235, 0.4649751527858088, 0.4721455949832417, 0.29453939909837545, 0.29453939909837545, 0.2818532422494564, 0.2818532422494564, 0.2818532422494564, 0.07170435622182425, 0.07170435622182425, 0.061776056698648274, 0.1047986441307408, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.44401542395966065, 0.44401542395966065, 0.44401542395966065, 0.07391061578141667, 0.020408131059997503, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfe8b727ff942c18e43012722972a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2006a7ec744efcbfaae230aa1b815f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2f514ed4c4461884b49ef505644963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.16822942837533583, 0.16822942837533583, 0.16822942837533583, 0.1108659565483775, 0.4478764110651998, 0.4721455949832417, 0.3673468850999958, 0.3673468850999958, 0.12465524317709276, 0.12465524317709276, 0.12465524317709276, 0.05681187406080768, 0.4120242658305403, 0.4721455949832417, 0.4495311386111467, 0.4495311386111467, 0.24875895434053985, 0.24875895434053985, 0.24875895434053985, 0.3314947398653363, 0.3314947398653363, 0.12300051563114589, 0.3083286857270906, 0.4721455949832417, 0.15499167376026612, 0.15499167376026612, 0.2471042267945931, 0.2471042267945931, 0.2471042267945931, 0.10921122900243063, 0.4660782825656049, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0, 0.0, 0.3182569852502666, 0.001103129779796319, 0.4721455949832417, 0.2504136818864867, 0.2504136818864867, 0.012134559082768392, 0.012134559082768392, 0.012134559082768392, 0.023717586151891235, 0.4649751527858088, 0.4721455949832417, 0.29453939909837545, 0.29453939909837545, 0.2818532422494564, 0.2818532422494564, 0.2818532422494564, 0.07170435622182425, 0.07170435622182425, 0.061776056698648274, 0.1047986441307408, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.44401542395966065, 0.44401542395966065, 0.44401542395966065, 0.07391061578141667, 0.020408131059997503, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b147f4509a49e4a1eaa8b9cc8f53a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438cae4794de4274bb59ff419d18c3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d44d1e84e604313833ba778f1e594f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.16822942837533583, 0.16822942837533583, 0.16822942837533583, 0.1108659565483775, 0.4478764110651998, 0.4721455949832417, 0.3673468850999958, 0.3673468850999958, 0.12465524317709276, 0.12465524317709276, 0.12465524317709276, 0.05681187406080768, 0.4120242658305403, 0.4721455949832417, 0.4495311386111467, 0.4495311386111467, 0.24875895434053985, 0.24875895434053985, 0.24875895434053985, 0.3314947398653363, 0.3314947398653363, 0.12300051563114589, 0.3083286857270906, 0.4721455949832417, 0.15499167376026612, 0.15499167376026612, 0.2471042267945931, 0.2471042267945931, 0.2471042267945931, 0.10921122900243063, 0.4660782825656049, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0, 0.0, 0.3182569852502666, 0.001103129779796319, 0.4721455949832417, 0.2504136818864867, 0.2504136818864867, 0.012134559082768392, 0.012134559082768392, 0.012134559082768392, 0.023717586151891235, 0.4649751527858088, 0.4721455949832417, 0.29453939909837545, 0.29453939909837545, 0.2818532422494564, 0.2818532422494564, 0.2818532422494564, 0.07170435622182425, 0.07170435622182425, 0.061776056698648274, 0.1047986441307408, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.44401542395966065, 0.44401542395966065, 0.44401542395966065, 0.07391061578141667, 0.020408131059997503, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.4721455949832417, 0.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/konstantinakovlev/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dff491e4beb4d4ea56257da66d5a8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338d7786db874dc18ba1d8ec51ab7123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c07bb2c65664d2c9661cda918bc2bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### find the best solution\n",
    "# import pickle\n",
    "# with open('./naive_mean.pckl', 'rb') as inp:\n",
    "#     eval_dict, fine_dict = pickle.loads(inp.read())\n",
    "eval_dict = {}\n",
    "fine_dict = {}\n",
    "\n",
    "# naive (proposed) or random importance\n",
    "random_importance = True\n",
    "\n",
    "for edge_mem in range(2,6):\n",
    "    if edge_mem in eval_dict and edge_mem in fine_dict:\n",
    "        print ('skip', edge_mem)\n",
    "        continue\n",
    "    #if edge_mem == 3 and attemp > 0:\n",
    "    #    continue\n",
    "    #if edge_mem == 4 and attemp > 0:\n",
    "    #    continue\n",
    "\n",
    "    model = ResNet18(len(cls))\n",
    "    model.model.fc.load_state_dict(torch.load('fc_best.ckpt', map_location='cpu'))\n",
    "    warp = GraphInterperterWithGamma(model)\n",
    "\n",
    "    named_dict = dict(model.named_modules())\n",
    "\n",
    "    for node in warp.graph.nodes:\n",
    "        if node.op == 'call_module':\n",
    "            pass\n",
    "            # print('Norm', np.sqrt(sum([(p ** 2).sum().item() \\\n",
    "            #                            for p in named_dict[node.target].parameters()])))\n",
    "        # print(node.op, node.name, node.args)\n",
    "        # break\n",
    "\n",
    "\n",
    "    edges, weights, a, b = module_to_graph(ResNet18())\n",
    "    # edges, weights\n",
    "    edges[:10], list(weights.items())[:10]\n",
    "    # edges_importance = [1]*len(edges)  ### WHY???\n",
    "    print(edges_importance)\n",
    "\n",
    "    best_pruned = 1e10\n",
    "    best_val = None\n",
    "    for s in tqdm(all_sorts, leave=False):\n",
    "        # for mem=8 the computation takes time\n",
    "        res = dp_for_top_sort(edges, {k: 1 for k in weights},\n",
    "                              edges_importance if not random_importance else [1] * len(edges),\n",
    "                              s, edge_mem)  \n",
    "        if res['connected_graph'] == True and best_pruned > res['pruned_value'] or best_val is None:\n",
    "            best_pruned = res['pruned_value']\n",
    "            best_val = res\n",
    "\n",
    "        if best_pruned == 0:\n",
    "            print(best_pruned)\n",
    "            # TODO: fix a bug with connected graph = False when pruned = 0\n",
    "            # print(res)\n",
    "            break\n",
    "\n",
    "\n",
    "    model = ResNet18(len(cls))\n",
    "    model.model.fc.load_state_dict(torch.load('fc_best.ckpt', map_location='cpu'))\n",
    "\n",
    "    wrapped = torch.fx.symbolic_trace(model)\n",
    "    pruned = PrunedModel(wrapped,\n",
    "                         {k:1.0 if k not in best_val['pruned_edges'] else 0.0 for k in edges},\n",
    "                         inter)\n",
    "\n",
    "    res = test_loop(pruned, test_dl, \"cpu\", nc=len(cls))\n",
    "    if edge_mem not in eval_dict:\n",
    "        eval_dict[edge_mem] = []\n",
    "    eval_dict[edge_mem].append(res)\n",
    "\n",
    "    train_loop(pruned, train_dl, test_dl, 9999999999, 1, 1e-3,  \"cpu\")\n",
    "    res = test_loop(pruned, test_dl,  \"cpu\", nc=len(cls))\n",
    "    if edge_mem not in fine_dict:\n",
    "        fine_dict[edge_mem] = []\n",
    "    fine_dict[edge_mem].append(res)\n",
    "\n",
    "    import pickle\n",
    "    with open('naive_mean.pckl' if not random_importance else 'random_mean.pckl', 'wb') as out:\n",
    "        out.write(pickle.dumps([eval_dict, fine_dict]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7abd6c68-9c8a-49e7-a624-c5bdccbeb84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.906499981880188],\n",
       "  3: [0.906499981880188],\n",
       "  4: [0.906499981880188],\n",
       "  5: [0.906499981880188]},\n",
       " {2: [0.953000009059906],\n",
       "  3: [0.8345000147819519],\n",
       "  4: [0.925000011920929],\n",
       "  5: [0.9514999985694885]}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('naive_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2fa972d-d74d-4012-a14a-dc7cb81c6ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{2: [0.5], 3: [0.5], 4: [0.5], 5: [0.5]},\n",
       " {2: [0.8544999957084656],\n",
       "  3: [0.9150000214576721],\n",
       "  4: [0.890500009059906],\n",
       "  5: [0.9330000281333923]}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('random_mean.pckl', 'rb') as inp:\n",
    "    data = pickle.loads(inp.read())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07b3b9-8840-4048-bb39-c5172c10a457",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The proposed pruning method substantially outperforms a random baseline\n",
    "in the case of a fair experimental protocol\n",
    "\n",
    "__TODO__: TODO: fix a bug with connected graph = False when pruned = 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae009c35-0559-44e6-b577-31fb42c15aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
